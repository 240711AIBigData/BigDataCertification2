# CHAPTER06 연습문제

SECTION01 단일 표본 검정
---
### ✏️ 문제
> 한 커피 제조회사에서는 새로 출시한 커피의 카페인 함량이 95mg 미만이라고 주장했다.<br>
> 그 주장이 사실인가를 알아보기 위해 25개의 커피 샘플을 무작위(랜덤)로 추출했다.<br>
> 커피 제조회사의 주장이 타당한지를 유의수준 5% 에서 검정하시오.

- 귀무가설(H₀) : μ >= 95mg (제조사의 주장이 틀렸다고 보는 관점)

  - 귀무가설은 대립가설을 반박할 기본적인 기준으로 설정(대립가설을 부정하는 형태)

- 대립가설(H₁) : μ < 95mg (제조사의 주장을 검증하려는 관점)


<br>

> 입력값
```python
  1. 표본 데이터의 평균
  
  2. Shapiro-Wilk 검정의 p-value
  
  3. 단일 표본 t-검정의 검정 통계량
  
  4. 단일 표본 t-검정의 p-value
  
  5. 유의수준 0.05 하에서 귀무가설을 기준으로 검정 결과를 채택/기각 중 선택
```

<br>

> 데이터
```python
  import pandas as pd
  df = pd.DataFrame({
      'Caffeine(mg)' : [
          94.2, 93.7, 95.5, 93.9, 94.0, 95.2, 94.7, 93.5, 92.8, 94.4,
          93.8, 94.6, 93.3, 95.1, 94.3, 94.9, 93.9, 94.8, 95.0, 94.2,
          93.7, 94.4, 95.1, 94.0, 93.6
      ]
  })
```

<br>

> 힌트
```python
  ttest_1samp()
```

<br>

#### 풀이
> 코드
```python
  # 1. 표본 평균
  print(df.mean())
  
  # 2. 정규성 검정
  from scipy import stats
  print(stats.shapiro(df['Caffeine(mg)']))
  
  # 3~5. 단일 표본 t-검정
  print(stats.ttest_1samp(df['Caffeine(mg)'], 95, alternative='less'))
  
  print(' ')
  
  statistic, pvalue = stats.ttest_1samp(df['Caffeine(mg)'], 95, alternative='less')
  print('{:.10f}'.format(pvalue))
```
- 지수 표기법을 일반 소수점 형태로 변경하기 위해 '{:.10f}'.format(pvalue) 사용

  - 소수 10번째 자리까지로 변경

> 결과
```python
  Caffeine(mg)    94.264
  dtype: float64
  ShapiroResult(statistic=0.9826578166170536, pvalue=0.9322031137746971)
  TtestResult(statistic=-5.501737036221897, pvalue=5.8686553916715e-06, df=24)
   
  0.0000058687
```
- Shapiro-Wilk 검정의 p-value 0.9826578166170536 > 0.05 : 데이터가 정규 분포를 따른다

- 단일 표본 t-검정의 검정 통게량 : -5.501737036221897, p-value : 0.0000058687(5.8686553916715e-06)

- 대립가설을 기준으로 df['Caffeine(mg)'] < 95 : alternative='less'

- p-value 0.00 < 유의수준 0.05 : 귀무가설 기각

<br>

> 정답
```python
  1. 표본 데이터의 평균 : 94.264
  
  2. Shapiro-Wilk 검정의 p-value : 0.9322031137746971
  
  3. 단일 표본 t-검정의 검정 통계량 : 5.501737036221897
  
  4. 단일 표본 t-검정의 p-value : 0.0000058687 (5.8686553916715e-06)
  
  5. 유의수준 0.05 하에서 귀무가설을 기준으로 검정 결과를 채택/기각 중 선택 : 기각 (p-value 0.00 < 유의수준 0.05)
```

<br>

---

<br>

SECTION02 독립 표본 검정
---
### ✏️ 문제
> 스마트폰 배터리의 충전 시간을 줄이기 위한 새로운 충전기를 개발했다. 개발된 충전기의 효과를 검정하기 위해<br>
> 스마트폰 사용자 집단을 두 그룹으로 나눠 한 그룹에는 새로운 충전기를 제공하고, 다른 그룹에는 기존 충전기를 제공했다.<br>
> 그 후 두 그룹의 평균 충전 완료 시간을 비교했다. 두 그룹 모두 충전 시간은 정규 분포를 따르며 분산은 같다고 가정한다.<br>
> 새로운 충전기가 더 빠르다고 할 수 있는지를 유의수준 5% 하에서 검정하시오.<br>
> (μ1 : 새로운 충전기 집단의 모평균, μ2 : 기존 충전기 집단의 모평균)

- 귀무가설(H₀) : μ1 >= μ2 (새로운 충전기가 더 빠르지 않다고 보는 관점)

  - 귀무가설은 대립가설을 반박할 기본적인 기준으로 설정(대립가설을 부정하는 형태)

- 대립가설(H₁) : μ1 < μ2 (새로운 충전기가 더 빠름을 검증하려는 관점)


<br>

> 입력값
```python
  1. 위 가설을 검정하기 위한 검정 통계량
  
  2. 위의 통계량에 대한 p-value
  
  3. 유의수준 0.05 하에서 귀무가설을 기준으로 검정의 결과를 채택/기각 중 선택
```

<br>

> 데이터
```python
  import pandas as pd
  df = pd.DataFrame({
      '충전기' : ['New'] * 10 + ['Old'] * 10,
      '충전시간' : [
          1.5, 1.6, 1.4, 1.7, 1.5, 1.6, 1.7, 1.4, 1.6, 1.5,
          1.7, 1.8, 1.7, 1.9, 1.8, 1.7, 1.8, 1.9, 1.7, 1.6
      ]
  })
  print(df.head(2))
```

> 결과
```python
     충전기  충전시간
  0  New   1.5
  1  New   1.6
```

<br>

> 힌트
```python
  ttest_ind()
```

<br>

#### 풀이
> 코드
```python
  # 1~3. 독립 표본 t-검정
  new_cond = df['충전기'] == 'New'
  old_cond = df['충전기'] == 'Old'
  print(df[new_cond]['충전시간'].head(2))
  print(df[old_cond]['충전시간'].head(2))
  
  print(' ')
  
  from scipy import stats
  print(stats.ttest_ind(df[new_cond]['충전시간'], df[old_cond]['충전시간'], alternative='less', equal_var=True))
```
- 스마트폰 충전기의 효과를 비교하는 데 있어서 두 독립된 집단 간의 평균을 비교하는데 초점

- 독립성 검정은 ttest_ind() 사용

  - 분산이 같다고 가정했기 때문에 equal_var=True 설정

> 결과
```python
  0    1.5
  1    1.6
  Name: 충전시간, dtype: float64
  10    1.7
  11    1.8
  Name: 충전시간, dtype: float64
   
  TtestResult(statistic=-4.582575694955849, pvalue=0.00011546547787696304, df=18.0)
```
- t-test 결과

  - p-value 0.00 < 유의수준 0.05 : 귀무가설 기각

<br>

> 정답
```python
  1. 위 가설을 검정하기 위한 검정 통계량 : -4.582575694955849
  
  2. 위의 통계량에 대한 p-value : 0.00011546547787696304
  
  3. 유의수준 0.05 하에서 귀무가설을 기준으로 검정의 결과를 채택/기각 중 선택 : 기각 (p-value 0.00 < 유의수준 0.05)
```

<br>

---

<br>

SECTION03 대응 표본 검정
---
### ✏️ 문제
> 연구소에서는 새로 개발한 교육과정에 참여하면 학습 시간이 단축된다고 주장한다.<br>
> 10명의 학생들을 대상으로 기존의 교육 방법과 새로운 교육 방법을 적용한 결과에 대해 유의수준 5% 에서<br>
> 새로운 교육방법이 교육 시간을 단축시켰는지 검정하시오. (단, 모집단은 정규 분포를 가정한다.)

- μd = (새로운 교육방법 - 기존 교육방법)의 평균

- 귀무가설(H₀) : μd >= 0 (새로운 교육방법의 학습 시간이 기존보다 길거나 같다고 보는 관점)

  - 귀무가설은 대립가설을 반박할 기본적인 기준으로 설정(대립가설을 부정하는 형태)

- 대립가설(H₁) : μd < 0 (새로운 교육방법이 학습 시간을 단축함을 검증하려는 관점)


<br>

> 입력값
```python
  1. μd 의 표본 평균 
  
  2. 위의 가설을 검정하기 위한 검정 통계량 
  
  3. 위의 통계량에 대한 p-value 
  
  4. 유의수준 0.05 하에서 귀무가설을 기준으로 검정의 결과를 채택/기각 중 선택 
```

<br>

> 데이터
```python
  import pandas as pd
  df = pd.DataFrame({
      'User' : list(range(1, 11)),
      '기존방법' : [60.4, 60.7, 60.5, 60.3, 60.8, 60.6, 60.2, 60.5, 60.7, 60.4],
      '새로운방법' : [59.8, 60.2, 60.1, 59.9, 59.7, 58.4, 57.0, 60.3, 59.6, 59.8]
  })
  print(df.head(2))
```

> 결과
```python
     User  기존방법  새로운방법
  0     1  60.4   59.8
  1     2  60.7   60.2
```

<br>

> 힌트
```python
  ttest_rel()
```

<br>

#### 풀이
> 코드
```python
  # 1. 표본 평균
  df['diff'] = df['새로운방법'] - df['기존방법']
  print(df['diff'].mean())
  
  # 2~4. 대응 표본 t-검정
  from scipy import stats
  print(stats.ttest_rel(df['새로운방법'], df['기존방법'], alternative='less'))
```
- μd : 새로운 방법 - 기존 방법

  - 차이 값을 diff 컬럼에 대입하고, 평균 구하기
 
- 대응 표본 t-검정은 ttest_rel() 사용

- μd 순서대로 새로운 방법, 기존 방법을 넣고, alternative 에는 대립가설 기준 첫 번째 값이 더 작아야 하므로 'less'

- t-test 결과

  - p-vlaue 0.00 < 유의수준 0.05 : 귀무가설 기각

> 결과
```python
  -1.0300000000000005
  TtestResult(statistic=-3.407973078114844, pvalue=0.0038872633380070652, df=9)
```

<br>

> 정답
```python
  1. μd 의 표본 평균 : -1.0300000000000005
  
  2. 위의 가설을 검정하기 위한 검정 통계량 : -3.407973078114844
  
  3. 위의 통계량에 대한 p-value : 0.0038872633380070652
  
  4. 유의수준 0.05 하에서 귀무가설을 기준으로 검정의 결과를 채택/기각 중 선택 : 기각 (p-vlaue 0.00 < 유의수준 0.05)
```

<br>

---

<br>

SECTION04 일원 분산 검정
---
### ✏️ 문제
> 4개의 중학교에서 다른 교육 방법을 사용해 학생들에게 수학을 가르쳤다.<br>
> 각 중학교의 학생들이 받은 교육 후의 수학 성적은 다음과 같다.<br>
> 이 4개의 교육 방법에 따른 성적 차이가 통계적으로 유의미한지 5% 유의수준에서 검정하시오.

- 귀무가설(H₀) : 모든 중학교의 학생들의 수학 성적은 평균은 동일하다

- 대립가설(H₁) : 적어도 2개 중학교의 학생들의 수학 성적 평균은 다르다

  - 4개 교육 방법 중 최소한 하나의 방법이 다른 방법들과 성적에서 차이가 있다

<br>

> 입력값
```python
  1. 각 그룹의 수학 성적에 대해 Shapiro-Wilk 검정을 통한 정규성 확인 후 그 결과의 p-value
  
  2. 4개 그룹의 수학 성적이 등분산성을 갖는지 확인하기 이ㅜ해 Levene 검정 후 p-value
  
  3. 유의수준 0.05 하에서 귀무가설을 기준으로 검정 결과를 채택/기각 중 선택
  
  4. 그룹 변수의 자유도
  
  5. 잔차의 자유도
  
  6. 성적의 제곱합
  
  7. 성적의 평균 제곱
  
  8. F-통계량 값
  
  9. 성적에 대한 p-value
```

<br>

> 데이터
```python
  import pandas as pd
  df = pd.read_csv('./data/math.csv')
  print(df.head())
```

> 결과
```python
      groups  scores
  0  group_A      85
  1  group_A      88
  2  group_A      90
  3  group_A      82
  4  group_A      87
```

<br>

> 힌트
```python
  shapiro(), levene(), f_oneway(), ols(), anova_lm()
```

<br>

#### 풀이
> 코드
```python
  from scipy import stats
  
  # 1. Shapiro-Wilk 검정 (정규성)
  condA = df['groups'] == 'group_A'
  print(stats.shapiro(df[condA]['scores']))
  
  condB = df['groups'] == 'group_B'
  print(stats.shapiro(df[condB]['scores']))
  
  condC = df['groups'] == 'group_C'
  print(stats.shapiro(df[condC]['scores']))
  
  condD = df['groups'] == 'group_D'
  print(stats.shapiro(df[condD]['scores']))
  
  print('')
  
  # 2. Levene 검정 (등분산성)
  print(stats.levene(df[condA]['scores'], df[condB]['scores'], df[condC]['scores'], df[condD]['scores']))
  
  print('')
  
  # 일원 분산 분석을 위한 모델 학습
  from statsmodels.formula.api import ols
  model = ols('scores ~ groups', df).fit()
  
  # 3~9. ANOVA 테이블
  from statsmodels.stats.anova import anova_lm  # 선형 모델을 명시적으로 생성한 후, 이를 anova_lm() 함수에 전달
  print(anova_lm(model))
```
- shapiro() 활용해 정규성 검정 실시

- 4개 그룹의 성적이 등분산성을 갖는지 Levene 검정 사용해 확인

- ols() 사용해 모델 학습 후, ANOVA 테이블 출력

  - 자유도(df), 총 제곱합(sum_sq), 평균 제곱(mean_sq), F-통계량(F), p-value(PR(>F))
 
  - 독립변수 groups 변수는 문자 ⇒ C() 사용여부와 관계없이 결과는 같음

> 결과
```python
  ShapiroResult(statistic=0.9715896670696531, pvalue=0.9051800443853569)
  ShapiroResult(statistic=0.9499422438060351, pvalue=0.6678172590861611)
  ShapiroResult(statistic=0.9299424104842702, pvalue=0.44732595113862045)
  ShapiroResult(statistic=0.9065684572704982, pvalue=0.25824165549017347)
  
  LeveneResult(statistic=1.757685352622062, pvalue=0.17270284963232108)
  
              df  sum_sq     mean_sq          F        PR(>F)
  groups     3.0   411.8  137.266667  34.174274  1.240642e-10
  Residual  36.0   144.6    4.016667        NaN           NaN
```
- ShapiroResult 의 각 pvalue 들 > 0.05 : 정규성에 만족한다

- LeveneResult 의 pvalue > 0.05 : 등분산성에 만족한다

- 일원 분산 분석 결과, p-value(0.00) < 유의수준(0.05) : 귀무가설 기각

<br>

> 정답
```python
  1. 각 그룹의 수학 성적에 대해 Shapiro-Wilk 검정을 통한 정규성 확인 후 그 결과의 p-value
      : 0.9051800443853569, 0.6678172590861611, 0.44732595113862045, 0.25824165549017347
  
  2. 4개 그룹의 수학 성적이 등분산성을 갖는지 확인하기 위해 Levene 검정 후 p-value : 0.17270284963232108
  
  3. 유의수준 0.05 하에서 귀무가설을 기준으로 검정 결과를 채택/기각 중 선택 : 기각 (p-value 0.00 < 유의수준 0.05)
  
  4. 그룹 변수의 자유도 : 3
  
  5. 잔차의 자유도 : 36
  
  6. 성적의 제곱합 : 411.8
  
  7. 성적의 평균 제곱 : 137.266667
  
  8. F-통계량 값 : 34.174274
  
  9. 성적에 대한 p-value : 1.240642e-10 (0.000000000124)
```

<br>

---

<br>

SECTION05 이원 분산 검정
---
### ✏️ 문제
> 토마토 연구소에서는 토마토의 수확량을 늘리기 위해 세 가지 다른 비료 유형과 네 가지 다른 물 주기를 실험하고자 한다.<br>
> 연구소에서는 12개의 토마토 식물을 무작위로 선택해 각 조합에 대해 반복적으로 실험을 수행했다.<br>

- 비료 유형에 따른 효과

  - 귀무가설(H₀) : 모든 비료 유형의 토마토 수확량 평균은 동일하다
  
  - 대립가설(H₁) : 적어도 2개 이상의 비료 유형에서의 토마토 수확량 평균이 다르다
 
- 물 주기에 따른 효과

  - 귀무가설(H₀) : 모든 물 주기의 토마토 수확량 평균은 동일하다
  
  - 대립가설(H₁) : 적어도 2개 이상의 물 주기에서의 토마토 수확량 평균이 다르다
 
- 비료 유형과 물 주기 간의 상호작용 효과

  - 귀무가설(H₀) : 비료 유형과 물 주기 간의 상호작용은 토마토 수확량에 영향을 미치지 않는다
  
  - 대립가설(H₁) : 비료 유형과 물 주기 간의 상호작용은 토마토 수확량에 영향을 미친다

<br>

> 입력값
```python
  1. 비료 유형에 따른 토마토 수확량의 평균에 차이가 있는지를 검정하기 위한 검정 통계량
  
  2. 위의 통계량에 대한 p-value
  
  3. 위의 검정 결과를 유의수준 0.05 하에서 귀무가설을 기준으로 채택/기각 중 선택
  
  4. 물 주기에 따른 토마토 수확량의 평균에 차이가 있는지를 검정하기 위한 검정 통계량
  
  5. 위의 통계량에 대한 p-value
  
  6. 위의 검정 결과를 유의수준 0.05 하에서 귀무가설 기준으로 채택/기각 중 선택
  
  7. 비료 유형과 물 주기 간의 상호작용이 토마토 수확량에 영향이 있는지 검정하기 위한 검정 통계량
  
  8. 위의 통계량에 대한 p-value
  
  9. 위의 검정 결과를 유의수준 0.05 하에서 귀무가설을 기준으로 채택/기각 중 선택 
```

<br>

> 데이터
```python
  import pandas as pd
  df = pd.read_csv('./data/tomato2.csv')
  print(df.head())
```

> 결과
```python
    비료유형  물주기  수확량
  0    A    1  514
  1    A    1  480
  2    A    1  507
  3    A    2  452
  4    A    2  526
```

<br>

> 힌트
```python
  ols(), anova_lm()
```

<br>

#### 풀이
> 코드
```python
  # R-style 공식(Syntax) 사용하여 모델을 간결하게 정의
  import statsmodels.api as sm
  from statsmodels.formula.api import ols
  
  # 1~9 이원 분산 분석
  model = ols('수확량 ~ C(비료유형) * C(물주기)', data=df).fit()
  anova_table = sm.stats.anova_lm(model)
  print(anova_table)
```

> 결과
```python
                    df        sum_sq      mean_sq         F    PR(>F)
  C(비료유형)          2.0   5251.722222  2625.861111  3.184685  0.059334
  C(물주기)           3.0   9057.000000  3019.000000  3.661490  0.026460
  C(비료유형):C(물주기)   6.0   4271.833333   711.972222  0.863491  0.535426
  Residual        24.0  19788.666667   824.527778       NaN       NaN
```
- 비료 유형에 대한 분석 F-통계량(3.184685), p-value(0.059334) : 귀무가설 채택

- 물 주기에 대한 분석 F-통계량(3.661490), p-value(0.026460) : 귀무가설 기각

- 비료 유형과 물 주기의 상호작용 효과에 대한 분석 F-통계량(0.863491), p-value(0.535426) : 귀무가설 채택

- df(자유도), sum_sq(총 제곱합), mean_sq(평균 제곱)

<br>

> 정답
```python

  1. 비료 유형에 따른 토마토 수확량의 평균에 차이가 있는지를 검정하기 위한 검정 통계량 : 3.184685
  
  2. 위의 통계량에 대한 p-value : 0.059334
  
  3. 위의 검정 결과를 유의수준 0.05 하에서 귀무가설을 기준으로 채택/기각 중 선택 : 채택 (0.059334 > 0.05)
  
  4. 물 주기에 따른 토마토 수확량의 평균에 차이가 있는지를 검정하기 위한 검정 통계량 : 3.661490
  
  5. 위의 통계량에 대한 p-value : 0.026460
  
  6. 위의 검정 결과를 유의수준 0.05 하에서 귀무가설 기준으로 채택/기각 중 선택 : 기각 (0.026460 < 0.05)
  
  7. 비료 유형과 물 주기 간의 상호작용이 토마토 수확량에 영향이 있는지 검정하기 위한 검정 통계량 : 0.863491
  
  8. 위의 통계량에 대한 p-value : 0.535426
  
  9. 위의 검정 결과를 유의수준 0.05 하에서 귀무가설을 기준으로 채택/기각 중 선택 : 채택 (0.535426 > 0.05)
```

<br>

<details>
  <summary>💡 statsmodels에서 anova_lm() 함수를 사용할 때, statsmodels.stats.anova 와 statsmodels.formula.api.ols </summary>

<br>

|특징|anova_lm 직접 사용|ols() + 공식 사용|
|:-:|:-:|:-:|
|입력 방식|수동으로 회귀 모델(sm.OLS) 생성 후 ANOVA 적용|공식(Syntax)로 범주형 변수와 상호작용 등을 처리|
|범주형 변수 처리|직접 변환 필요|자동으로 처리|
|상호작용 처리|수동 처리 필요|* 연산자로 간단히 처리|
|유연성|데이터 전처리 및 사용자 정의 가능|제한적(공식 기반)|
|코드 간결성|상대적으로 복잡|간단하고 직관적|

</details>

<br>

---

<br>

SECTION06 적합도 검정
---
### ✏️ 문제
> 한 도시의 운전자 1,000명을 대상으로 교통사고 경험 수를 조사했다. 1회: 550명, 2회: 250명, 3회: 100명, 4회: 70명, 5회 이상: 30명이다.<br>
> 전국적으로 조사된 데이터에 따르면 운전자들의 교통사고 경험 수 분포는 다음과 같다.<br>
> 1회: 60%, 2회: 25%, 3회: 8%, 4회: 5%, 5회 이상: 2% 다. <br>
> 이 도시 운전자들의 교통사고 경험 수 분포가 전국적인 경향을 따르는지 검정하시오. (유의수준 0.05)

- 귀무가설(H₀) : 이 도시의 교통사고 경험 수 분포는 전국적인 경향을 따른다

- 대립가설(H₁) : 이 돋시의 교통사고 경험 수 분포는 전국적인 경향을 따르지 않는다

|구분|경험 수|전국적인 경향(%)|
|:-:|:-:|:-:|
|1회|550|60%|
|2회|250|25%|
|3회|100|8%|
|4회|70|5%|
|5회|30|2%|

<br>

> 입력값
```python
  1. 이 도시의 교통사고 경험자 중 5회 이상의 비율(0과 1 사이)
  
  2. 이 도시 운전자들의 교통사고 경험 수 분포가 전국적인 경향을 따르는지 검정하기 위한 검정 통계량
  
  3. 위의 통계량에 대한 p-value
  
  4. 위의 검정 결과를 유의수준 0.05 하에서 귀무가설을 기준으로 채택/기각 중 선택
```

<br>

> 힌트
```python
  chisquare()
```

<br>

#### 풀이
> 코드
```python
  # 1. 교통사고 5회 이상 경험 비율
  print(30/1000)
  
  # 2~4. 적합도 검정
  from scipy.stats import chisquare
  observed = [550, 250, 100, 70, 30]
  expected = [1000*0.60, 1000*0.25, 1000*0.08, 1000*0.05, 1000*0.02]
  print(chisquare(observed, expected))
```
- 교통사고 5회 이상 경험은 1,000명 중 30명 (비율 : 0.03)

- 적합도 검정을 위해 관측치와 기대값을 리스트에 담기

  - 모두 빈도 수로 통일
 
- 관측치인 한 도시의 교통사고 경험 수(빈도)는 observed 변수에 순서대로 입력

- 기대값인 전국적인 교통사고 경험 수(빈도)는 expected 변수에 입력

  - 관측치의 총합은 1,000
 
  - 전국적인 경향(확률값)에 1,000 을 곱해 빈도 값 구하기
 
- chisqaure() 함수를 통해 적합도 검정 실시 후 검정 통계량, p-value 확인

> 결과
```python
  0.03
  Power_divergenceResult(statistic=22.166666666666668, pvalue=0.00018567620386641427)
```
- p-value 0.00 < 유의수준 0.05 : 귀무가설 기각

  - 이 도시의 교통사고 경험 수 분포는 전국적인 경향을 따르지 않음

<br>

> 정답
```python
  1. 이 도시의 교통사고 경험자 중 5회 이상의 비율(0과 1 사이) : 0.03
  
  2. 이 도시 운전자들의 교통사고 경험 수 분포가 전국적인 경향을 따르는지 검정하기 위한 검정 통계량 : 22.166666666666668
  
  3. 위의 통계량에 대한 p-value : 0.00018567620386641427
  
  4. 위의 검정 결과를 유의수준 0.05 하에서 귀무가설을 기준으로 채택/기각 중 선택 : 기각
```

<br>

---

<br>

SECTION07 독립성 검정
---
### ✏️ 문제
> 빅데이터 분석기사 캠프와 정보처리기사 캠프가 있다. 최근 두 캠프 학생들 사이에서 주최한 세미나에 참여하려면 등록을 해야 한다.<br>
> 각 캠프의 세미나 등록 여부를 조사한 결과는 아래와 같다. 캠프와 세미나 등록 여부가 서로 독립적인지 검정하시오. (유의수준 0.05)

- 귀무가설(H₀) : 캠프와 세미나 등록 여부는 서로 독립적이다

- 대립가설(H₁) : 캠프와 세미나 등록 여부는 서로 독립적이 아니다

<br>

> (1) 교차표 데이터가 주어졌을 때

|구분|등록함|등록 안함|
|:-:|:-:|:-:|
|빅데이터 분석기사 캠프|50|30|
|정보처리기사 캠프|60|40|

<br>

> (2) 로우 데이터가 주어졌을 때
```python
  import pandas as pd
  df = pd.DataFrame({
      '캠프' : ['빅분기']*80 + ['정처기']*100,
      '등록여부' : ['등록']*50 + ['등록안함']*30 + ['등록']*60 + ['등록안함']*40
  })
  print(df.head())
```

> 결과
```python
      캠프 등록여부
  0  빅분기   등록
  1  빅분기   등록
  2  빅분기   등록
  3  빅분기   등록
  4  빅분기   등록
```
- 로우(원) 데이터 형태로 csv 파일이 주어졌을 때는 교차표 형태로 재구조화 필요

<br>

> 입력값
```python
  (1) 교차표 데이터가 주어졌을 때
  1. 캠프와 세미나 등록 여부가 서로 독립적인지를 검정하기 위한 검정 통계량
  
  2. 위의 통계량에 대한 p-value
  
  3. 위의 검정 결과를 유의수준 0.05 하에서 귀무가설을 기준으로 채택/기각 중 선택
  
  (2) 로우 데이터가 주어졌을 때
  4. 캠프와 세미나 등록 여부가 서로 독립적인지를 검정하기 위한 검정 통계량
  
  5. 위의 통계량에 대한 p-value
  
  6. 위의 검정 결과를 유의수준 0.05 하에서 귀무가설을 기준으로 채택/기각 중 선택
```

<br>

> 힌트
```python
  chi2_contingency(observed)
```

<br>

#### 풀이
> (1) 코드
```python
  import pandas as pd
  from scipy.stats import chi2_contingency
  
  # 1~3. 독립성 검정
  observed = pd.DataFrame([[50, 30], [60, 40]])
  print(chi2_contingency(observed))
```
- 문제에서 제시된 표를 바탕으로 교차표를 데이터프레임으로 만들기

- chi2_contingency() 함수를 활용해 검정 통계량과 p-value 구하기

> 결과
```python
  Chi2ContingencyResult(statistic=0.03535714285714309, pvalue=0.8508492527705047, dof=1, expected_freq=array([[48.88888889, 31.11111111],
         [61.11111111, 38.88888889]]))
```
- p-value 0.85 > 유의수준 0.05 : 귀무가설 채택

<br>

> (2) 코드
```python
  # 교차표로 변경
  df = pd.crosstab(df['캠프'], df['등록여부'])
  print(df)
  
  # 4~6. 독립성 검정
  print(chi2_contingency(df))
```
- pd.crosstab() 함수를 사용해 교차표 형태로 변경

- chi2_contingency() 함수를 활용해 검정 통계량과 p-value 확인

> 결과
```python
  등록여부  등록  등록안함
  캠프            
  빅분기   50    30
  정처기   60    40
  Chi2ContingencyResult(statistic=0.03535714285714309, pvalue=0.8508492527705047, dof=1, expected_freq=array([[48.88888889, 31.11111111],
         [61.11111111, 38.88888889]]))
```
- p-value 0.85 > 유의수준 0.05 : 귀무가설 채택

- 빅분기 캠프에서 등록할 것으로 기대되는 빈도 : 48.9, 등록하지 않을 것으로 기대되는 빈도 : 31.1

- 정처기 캠프에서 등록할 것으로 기대되는 빈도 : 61.1, 등록하지 않을 것으로 기대되는 빈도 : 38.9

<br>

> 정답
```python
  (1) 교차표 데이터가 주어졌을 때
  1. 캠프와 세미나 등록 여부가 서로 독립적인지를 검정하기 위한 검정 통계량 : 0.03535714285714309
  
  2. 위의 통계량에 대한 p-value : 0.8508492527705047
  
  3. 위의 검정 결과를 유의수준 0.05 하에서 귀무가설을 기준으로 채택/기각 중 선택 : 채택
  
  (2) 로우 데이터가 주어졌을 때
  4. 캠프와 세미나 등록 여부가 서로 독립적인지를 검정하기 위한 검정 통계량 : 0.03535714285714309
  
  5. 위의 통계량에 대한 p-value : 0.8508492527705047
  
  6. 위의 검정 결과를 유의수준 0.05 하에서 귀무가설을 기준으로 채택/기각 중 선택 : 채택
```

<br>

---

<br>

SECTION08 다중 선형 회귀
---
### ✏️ 문제
> 한 도시의 배달 서비스 회사에서 한 달 동안 주문 데이터를 수집했다.<br>
> 배달 주문량은 할인율(%), 온도(°C), 광고비(천 원)와 같은 다양한 요인들에 영향을 받을 수 있다.<br>
> 배달 서비스 회사는 이런 요인들을 고려해 주문량을 예측하고자 한다.<br>
> 할인율, 온도, 광고비를 독립변수로 사용해 다중 선형 회귀 모델을 구축하고, 다음 문제에 답하시오.<br>

<br>

> 입력값
```python
  1. 할인율과 온도의 상관 계수(반올림하여 소수 둘째 자리까지)
  
  2. 모델의 결정 계수(반올림하여 소수 둘째 자리까지)
  
  3. 각 변수의 회귀 계수(반올림하여 소수 넷째 자리까지)
  
  4. 모델의 절편(Intercept)(반올림하여 소수 넷째 자리까지)
  
  5. 온도의 회귀 계수가 통계적으로 유의한지 검정(p-value 반올림하여 소수 넷째 자리까지)
  
  6. 데이터가 할인율이 10%, 온도가 20°C, 광고비가 500,000원일 때 배0달 주문량 예측
  
  7. 잔차 제곱합
  
  8. MSE
  
  9. 온도의 회귀 계수에 대한 90% 신회 구간
  
  10. 데이터가 할인율이 15%, 온도가 25°C, 광고비가 300,000원일 때 90% 신뢰 구간과 예측 구간
  
  11. 독립변수 할인율과 온도를 고정한 상태에서 광고비가 배달 주문량에 영향을 주는지 가설 검정
      유의수준 0.05 기준으로 귀무가설 기각/채택 선택
        - 귀무가설(H₀) : 광고비의 회귀 계수는 0이다 (광고비가 배달 주문량에 영향을 주지 않는다)
        
        - 대립가설(H₁) : 광고비의 회귀 계수는 0이 아니다 (광고비가 배달 주문량에 영향을 준다)
```
- 독립변수 할인율과 온도가 고정될 때

  - 이런 변수들의 값이 변하지 않는 상황에서 광고비가 배달주문량에 미치는 영향만을 분리해 검토
 
  - 할인율과 온도를 일정하게 유지한 상태에서 광고 지출의 변화가 주문량에 어떤 영향을 미치는지 분석
 
- 회귀계수의 유의성 검정은 일반적으로 t-test 사용해 수행

  - 귀무가설 : 광고비의 회귀 계수 = 0
 
    - 귀무가설 기각되면 광고비가 주문량에 유의미한 영향을 미침
   
    - 광고비를 변화시킴으로써 주문량의 변동을 일으킬 수 있다는 의미

<br>

> 데이터
```python
  import pandas as pd
  df = pd.DataFrame({
      '할인율' : [28, 24, 13, 0, 27, 30, 10, 16, 6, 5, 7, 11, 11, 30, 25,
              4, 7, 24, 19, 21, 6, 10, 26, 13, 15, 6, 12, 6, 20, 2],
      '온도' : [15, 34, 15, 22, 29, 30, 14, 17, 28, 29, 19, 19, 34, 10, 29,
              28, 12, 25, 32, 28, 22, 16, 30, 11, 16, 18, 16, 33, 12, 22],
      '광고비' : [342, 666, 224, 764, 148, 499, 711, 596, 797, 484, 986, 347, 146, 362, 642,
              591, 846, 260, 560, 941, 469, 309, 730, 305, 892, 147, 887, 526, 525, 884],
      '주문량' : [635, 958, 525, 25, 607, 872, 858, 732, 1082, 863, 904, 686, 699, 615, 893,
              830, 856, 679, 918, 951, 789, 583, 988, 631, 866, 549, 910, 946, 647, 943]
  })
  print(df.head(3))
```

> 결과
```python
     할인율  온도  광고비  주문량
  0   28  15  342  635
  1   24  34  666  958
  2   13  15  224  525
```

<br>

> 힌트
```python
  ols()
```

<br>

#### 풀이
> 코드
```python  
  # 다중 선형 회귀 모델 적합
  from statsmodels.formula.api import ols
  model = ols('주문량 ~ 할인율 + 온도 + 광고비', data=df).fit()
  
  # 1. 상관 계수
  print('1. 상관 계수 :', round(df['할인율'].corr(df['온도']), 2))
  
  # 2. 결정 계수
  print('2. 결정 계수(R-squared) :', round(model.rsquared, 2))
  
  # 3. 회귀 계수(기울기)
  print('3. 회귀 계수 :\n', round(model.params, 4))
  
  # 4. 절편
  print('4. 절편 :', round(model.params['Intercept'], 4))
  
  # 5. 회귀 계수 검정
  print('5. p-value :', round(model.pvalues['온도'], 4))
  
  # 6. 예측 판매량
  new_data = pd.DataFrame({
      '할인율' : [10],
      '온도' : [20],
      '광고비' : [500]
  })
  result = model.predict(new_data)
  print('6. 새로운 데이터 :', int(result[0]))
  
  # 7. 잔차 제곱합
  df['잔차'] = df['주문량'] - model.predict(df)
  print('7. 잔차 제곱합 :', round(sum(df['잔차']**2), 2))
  
  # 8. MSE(Mean Squared Error)
  MSE = (df['잔차']**2).mean()
  print('8. MSE :', round(MSE, 4))
  
  # 9. 각 변수에 대한 90% 신뢰 구간
  print('9. 신뢰구간 :\n', model.conf_int(alpha=0.1))
  
  # 10. 새로운 데이터의 예측값의 90% 신뢰 구간과 예측 구간
  new_data = pd.DataFrame({
      '할인율' : [15],
      '온도' : [25],
      '광고비' : [300]
  })
  pred = model.get_prediction(new_data)
  result = pred.summary_frame(alpha=0.1)
  print('10. 예측값의 신뢰 구간과 예측 구간 :\n', result)
  
  # 11. 광고비는 배달 주문량에 영향을 주는지 가설 검정
  cond = model.pvalues['광고비']<0.05
  if cond:
      result = '기각'
  else :
      result = '채택'
  print('11. 귀무가설 :', result)
  
  # 선형 회귀 모델의 요약 결과
  print(model.summary())
```

> 결과
```python
  1. 상관 계수 : 0.09
  2. 결정 계수(R-squared) : 0.4
  3. 회귀 계수 :
   Intercept    267.6609
  할인율            4.2068
  온도             9.4798
  광고비            0.4148
  dtype: float64
  4. 절편 : 267.6609
  5. p-value : 0.0289
  6. 새로운 데이터 : 706
  7. 잔차 제곱합 : 732197.9
  8. MSE : 24406.5966
  9. 신뢰구간 :
                      0           1
  Intercept  45.955720  489.366084
  할인율        -1.847229   10.260887
  온도          2.490702   16.468984
  광고비         0.201064    0.628589
  10. 예측값의 신뢰 구간과 예측 구간 :
            mean    mean_se  mean_ci_lower  mean_ci_upper  obs_ci_lower  \
  0  692.207386  45.555397     614.507283     769.907488    395.622293   
  
     obs_ci_upper  
  0    988.792478  
  11. 귀무가설 : 기각
                              OLS Regression Results                            
  ==============================================================================
  Dep. Variable:                    주문량   R-squared:                       0.400
  Model:                            OLS   Adj. R-squared:                  0.330
  Method:                 Least Squares   F-statistic:                     5.770
  Date:                Wed, 20 Nov 2024   Prob (F-statistic):            0.00366
  Time:                        17:01:17   Log-Likelihood:                -194.11
  No. Observations:                  30   AIC:                             396.2
  Df Residuals:                      26   BIC:                             401.8
  Df Model:                           3                                         
  Covariance Type:            nonrobust                                         
  ==============================================================================
                   coef    std err          t      P>|t|      [0.025      0.975]
  ------------------------------------------------------------------------------
  Intercept    267.6609    129.985      2.059      0.050       0.472     534.849
  할인율            4.2068      3.549      1.185      0.247      -3.089      11.503
  온도             9.4798      4.098      2.313      0.029       1.057      17.903
  광고비            0.4148      0.125      3.310      0.003       0.157       0.672
  ==============================================================================
  Omnibus:                       56.788   Durbin-Watson:                   1.647
  Prob(Omnibus):                  0.000   Jarque-Bera (JB):              419.005
  Skew:                          -3.845   Prob(JB):                     1.03e-91
  Kurtosis:                      19.616   Cond. No.                     2.58e+03
  ==============================================================================
  
  Notes:
  [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
  [2] The condition number is large, 2.58e+03. This might indicate that there are
  strong multicollinearity or other numerical problems.
```

<br>

---

<br>

SECTION09 로지스틱 회귀
---



<br>
















