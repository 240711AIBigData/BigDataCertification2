# CHAPTER07 ë‹¤ì¤‘ ë¶„ë¥˜ ì—°ìŠµë¬¸ì œ
- ë‹¤ì¤‘ ë¶„ë¥˜ëŠ” ì—¬ëŸ¬ ê°œì˜ í´ë˜ìŠ¤ ì¤‘ í•˜ë‚˜ë¥¼ ì˜ˆì¸¡

- ì´ì§„ ë¶„ë¥˜ì™€ í¬ê²Œ ë‹¤ë¥´ì§€ ì•Šìœ¼ë‚˜, í‰ê°€ì§€í‘œ ì‚¬ìš©í•  ë•Œ ì°¨ì´ì  ìˆìŒ

<br>

SECTION01 ì‹ ìš© ë“±ê¸‰ ì˜ˆì¸¡
---
- ì€í–‰ ì •ë³´ë¡œ ì‹ ìš© ë“±ê¸‰ ì˜ˆì¸¡

  - ì œê³µëœ ë°ì´í„° ëª©ë¡ : score_train.csv, score_test.csv
 
  - ì˜ˆì¸¡í•  ì»¬ëŸ¼ : Credit_Score(Good, Standard, Poor)
 
- í•™ìŠµìš© ë°ì´í„°(train)ë¥¼ ì´ìš©í•´ ì‹ ìš© ë“±ê¸‰ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ ìƒì„±

- í‰ê°€ìš© ë°ì´í„°(test)ì— ì ìš©í•´ ì–»ì€ ì˜ˆì¸¡ê°’ì„ ì•„ë˜ í˜•ì‹ì˜ csv íŒŒì¼ë¡œ ìƒì„±

  - ì œì¶œ íŒŒì¼ì€ ë‹¤ìŒ 1ê°œì˜ ì»¬ëŸ¼ì„ í¬í•¨
 
    - pred : ì˜ˆì¸¡ê°’
   
    - ì œì¶œ íŒŒì¼ëª… : 'result1.csv'
   
  - ì œì¶œí•œ ëª¨ë¸ì˜ ì„±ëŠ¥ì€ f1-macro í‰ê°€ì§€í‘œì— ë”°ë¼ ì±„ì 

<br>

### 01. ë² ì´ìŠ¤ë¼ì¸
- ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ê³ , ê°„ë‹¨í•œ íƒìƒ‰ì  ë°ì´í„° ë¶„ì„ ì§„í–‰

<br>

#### (1) EDA
> ì½”ë“œ
```python
  # 1. ë¬¸ì œì •ì˜
  # í‰ê°€ : f1-macro
  # target : Credit_Score
  # ìµœì¢… íŒŒì¼ : result1.csv(ì»¬ëŸ¼ 1ê°œ pred)
  
  # ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
  import pandas as pd
  
  train = pd.read_csv('./data/score_train.csv')
  test = pd.read_csv('./data/score_test.csv')
  
  # 3. íƒìƒ‰ì  ë°ì´í„° ë¶„ì„(EDA)
  print('==== ë°ì´í„° í¬ê¸° ====')
  print('train shape :', train.shape)
  print('test shape :', test.shape)
  print('\n')     # ì¤„ ë°”ê¿ˆ
  
  print('==== ë°ì´í„° ì •ë³´(ìë£Œí˜•) ====')
  print(train.info())
  print('\n')
  
  print('==== train ê²°ì¸¡ì¹˜ ìˆ˜ ====')
  print(train.isnull().sum())
  print('\n')
  
  print('==== test ê²°ì¸¡ì¹˜ ìˆ˜ ====')
  print(test.isnull().sum())
  print('\n')
  
  print('==== target ë¹ˆë„ ====')
  print(train['Credit_Score'].value_counts())
```

> ê²°ê³¼
```python
  ==== ë°ì´í„° í¬ê¸° ====
  train shape : (4198, 21)
  test shape : (1499, 20)
  
  
  ==== ë°ì´í„° ì •ë³´(ìë£Œí˜•) ====
  <class 'pandas.core.frame.DataFrame'>
  RangeIndex: 4198 entries, 0 to 4197
  Data columns (total 21 columns):
   #   Column                    Non-Null Count  Dtype  
  ---  ------                    --------------  -----  
   0   Delay_from_due_date       4198 non-null   float64
   1   Num_of_Delayed_Payment    4198 non-null   float64
   2   Num_Credit_Inquiries      4198 non-null   float64
   3   Credit_Utilization_Ratio  4198 non-null   float64
   4   Credit_History_Age        4198 non-null   float64
   5   Payment_of_Min_Amount     4198 non-null   object 
   6   Amount_invested_monthly   4198 non-null   float64
   7   Monthly_Balance           4198 non-null   float64
   8   Credit_Mix                4198 non-null   object 
   9   Payment_Behaviour         4198 non-null   object 
   10  Age                       4198 non-null   float64
   11  Annual_Income             4198 non-null   float64
   12  Num_Bank_Accounts         4198 non-null   float64
   13  Num_Credit_Card           4198 non-null   float64
   14  Interest_Rate             4198 non-null   float64
   15  Num_of_Loan               4198 non-null   float64
   16  Monthly_Inhand_Salary     4198 non-null   float64
   17  Changed_Credit_Limit      4198 non-null   float64
   18  Outstanding_Debt          4198 non-null   float64
   19  Total_EMI_per_month       4198 non-null   float64
   20  Credit_Score              4198 non-null   object 
  dtypes: float64(17), object(4)
  memory usage: 688.9+ KB
  None
  
  
  ==== train ê²°ì¸¡ì¹˜ ìˆ˜ ====
  Delay_from_due_date         0
  Num_of_Delayed_Payment      0
  Num_Credit_Inquiries        0
  Credit_Utilization_Ratio    0
  Credit_History_Age          0
  Payment_of_Min_Amount       0
  Amount_invested_monthly     0
  Monthly_Balance             0
  Credit_Mix                  0
  Payment_Behaviour           0
  Age                         0
  Annual_Income               0
  Num_Bank_Accounts           0
  Num_Credit_Card             0
  Interest_Rate               0
  Num_of_Loan                 0
  Monthly_Inhand_Salary       0
  Changed_Credit_Limit        0
  Outstanding_Debt            0
  Total_EMI_per_month         0
  Credit_Score                0
  dtype: int64
  
  
  ==== test ê²°ì¸¡ì¹˜ ìˆ˜ ====
  Delay_from_due_date         0
  Num_of_Delayed_Payment      0
  Num_Credit_Inquiries        0
  Credit_Utilization_Ratio    0
  Credit_History_Age          0
  Payment_of_Min_Amount       0
  Amount_invested_monthly     0
  Monthly_Balance             0
  Credit_Mix                  0
  Payment_Behaviour           0
  Age                         0
  Annual_Income               0
  Num_Bank_Accounts           0
  Num_Credit_Card             0
  Interest_Rate               0
  Num_of_Loan                 0
  Monthly_Inhand_Salary       0
  Changed_Credit_Limit        0
  Outstanding_Debt            0
  Total_EMI_per_month         0
  dtype: int64
  
  
  ==== target ë¹ˆë„ ====
  Credit_Score
  Standard    2225
  Poor        1232
  Good         741
  Name: count, dtype: int64
```
- train ë°ì´í„°ì˜ ìë£Œí˜• : float64 17ê°œ, object 4ê°œ

- target : ì„¸ ê°€ì§€ ì¹´í…Œê³ ë¦¬(í´ë˜ìŠ¤)ê°€ ìˆëŠ” object ìë£Œí˜•

  - ì¸ì½”ë”©í•  ê²½ìš° target ì»¬ëŸ¼ ì œì™¸
 
    - target ì»¬ëŸ¼ ì›-í•« ì¸ì½”ë”©í•  ê²½ìš° target ì»¬ëŸ¼ì´ 1ê°œê°€ ì•„ë‹Œ ì—¬ëŸ¬ê°œ ë§Œë“¤ì–´ì§
   
    - ë ˆì´ë¸” ì¸ì½”ë”©ì€ ê°€ëŠ¥í•˜ì§€ë§Œ, 0, 1, 2 ë¡œ ë³€ê²½í•œ í›„ ë§ˆì§€ë§‰ csv ì œì¶œì—ì„œ ë‹¤ì‹œ Good, Standard, Poor ë¡œ ë³µì›í•´ì•¼ í•¨
   
    - ëœë¤í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ì€ target ì´ object ë”ë¼ë„ ìë™ìœ¼ë¡œ ì¸ì‹í•´ ìˆ˜ì¹˜í˜•ìœ¼ë¡œ ì¸ì½”ë”© ì—†ì´ ì‚¬ìš© ê°€ëŠ¥

- ê²°ì¸¡ì¹˜ ì—†ìŒ

<br>

#### (2) ì „ì²˜ë¦¬ ë° ì˜ˆì¸¡
- í‰ê°€ì§€í‘œ : f1-macro

  - ì´ì§„ë¶„ë¥˜ì™€ ê°™ì´ F1 ìŠ¤ì½”ì–´ í‰ê°€ì§€í‘œ ì‚¬ìš©í•˜ë˜, average='macro' ì„¤ì •
 
> ì½”ë“œ
```python
  # 4. ë°ì´í„° ì „ì²˜ë¦¬
  # ì›-í•« ì¸ì½”ë”©(target ì»¬ëŸ¼ì´ object í˜•ì´ë¼ ì œì™¸)
  target = train.pop('Credit_Score')
  
  train = pd.get_dummies(train)
  test = pd.get_dummies(test)
  
  # 5. ê²€ì¦ ë°ì´í„° ë‚˜ëˆ„ê¸°
  from sklearn.model_selection import train_test_split
  X_train, X_val, y_train, y_val = train_test_split(train, target, test_size=0.2, random_state=0)
  
  print('\n==== ë¶„í• ëœ ë°ì´í„° í¬ê¸° ====')
  print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)
  
  # 6. ë¨¸ì‹ ëŸ¬ë‹ í•™ìŠµ ë° í‰ê°€
  from sklearn.ensemble import RandomForestClassifier
  rf = RandomForestClassifier(random_state=0)
  rf.fit(X_train, y_train)
  pred = rf.predict(X_val)
  
  from sklearn.metrics import f1_score
  f1 = f1_score(y_val, pred, average='macro')
  print('\nf1-macro :', f1)
  
  # 7. ì˜ˆì¸¡ ë° ê²°ê³¼ íŒŒì¼ ìƒì„±
  pred = rf.predict(test)
  submit = pd.DataFrame({'pred':pred})
  submit.to_csv('result1.csv', index=False)
  
  # ì œì¶œ íŒŒì¼ í™•ì¸
  print('\n==== ì œì¶œ íŒŒì¼ (ìƒ˜í”Œ 5ê°œ) ====')
  print(pd.read_csv('result1.csv').head())
```

> ê²°ê³¼
```python
  ==== ë¶„í• ëœ ë°ì´í„° í¬ê¸° ====
  (3358, 29) (840, 29) (3358,) (840,)
  
  f1-macro : 0.7004593488873695
  
  ==== ì œì¶œ íŒŒì¼ (ìƒ˜í”Œ 5ê°œ) ====
         pred
  0      Poor
  1      Good
  2  Standard
  3      Good
  4  Standard
```

<br>

### 02. ì„±ëŠ¥ ê°œì„ 
- ê°„ë‹¨í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ìœ¼ë¡œëŠ” ì„±ëŠ¥ í–¥ìƒ ì‹¤íŒ¨

  - ì„±ëŠ¥ì´ í–¥ìƒë˜ì§€ ì•ŠëŠ” ì¼€ì´ìŠ¤ì—ì„  íŠœë‹ì„ ë” í•˜ê¸°ë³´ë‹¨ ì‘ì—…í•œ ë‚´ìš© ì¤‘ ìµœê³  ì ìˆ˜ ì œì¶œ
 
- ë°ì´í„° ì „ì²˜ë¦¬

  - ë ˆì´ë¸” ì¸ì½”ë”© : ì„±ëŠ¥ì´ ì˜¤íˆë ¤ ë–¨ì–´ì§
 
  - ìŠ¤ì¼€ì¼ë§(Standard Scaler) : ì•½ê°„ì˜ ë³€í™” í™•ì¸ë¨
 
- í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹

  - max_depth : 5 ~ 10, ì´ì§„ ë¶„ë¥˜ë³´ë‹¤ëŠ” ì¢€ ë” ê¹Šì´ë¥¼ ê¹Šê²Œ ì„¤ì •
 
  - n_setimators : 200 ~ 500

<BR>

|ë°ì´í„° ì „ì²˜ë¦¬/í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹|F1|ì œì¶œ|
|-|-|-|
|ë² ì´ìŠ¤ë¼ì¸|0.7004593488873695|ì„ íƒ / 1ì°¨ ì œì¶œ|
|ë ˆì´ë¸” ì¸ì½”ë”©|0.6853171856067161||
|ìŠ¤ì¼€ì¼ë§(Standard Scaler)|0.7020460066061172|ì„ íƒ / 2ì°¨ ì œì¶œ|
|ìŠ¤ì¼€ì¼ë§(Min-Max Scaler)|0.7006138262986147||
|ìŠ¤ì¼€ì¼ë§(Robust Scaler)|0.6988656925588274||
|max_depth = 5|0.6766506819894232||
|max_depth = 7|0.6870057878861987||
|max_depth = 10|0.6916940184736795||
|n_estimators = 200|0.6962063487956804||
|n_estimators = 400|0.6940222897669707||
|n_estimators = 500|0.6928450293038421||

<br>

> ì½”ë“œ
```python
  # 2. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
  import pandas as pd
  
  train = pd.read_csv('./data/score_train.csv')
  test = pd.read_csv('./data/score_test.csv')
  
  # 4. ë°ì´í„° ì „ì²˜ë¦¬
  target = train.pop('Credit_Score')
  
  # ìŠ¤ì¼€ì¼ë§
  from sklearn.preprocessing import StandardScaler
  scaler = StandardScaler()
  cols = train.select_dtypes(exclude='object').columns
  train[cols] = scaler.fit_transform(train[cols])
  test[cols] = scaler.transform(test[cols])
  
  # ì›-í•« ì¸ì½”ë”©
  train = pd.get_dummies(train)
  test = pd.get_dummies(test)
  
  # ë ˆì´ë¸” ì¸ì½”ë”© : ì„±ëŠ¥ ë–¨ì–´ì§ ì£¼ì„ì²˜ë¦¬
  # from sklearn.preprocessing import LabelEncoder
  # cols = train.select_dtypes(include='object').columns
  # for col in cols:
  #     le = LabelEncoder()
  #     train[col] = le.fit_transform(train[col])
  #     test[col] = le.transform(test[col])
      
  # 5. ê²€ì¦ ë°ì´í„° ë‚˜ëˆ„ê¸°
  from sklearn.model_selection import train_test_split
  X_train, X_val, y_train, y_val = train_test_split(train, target, test_size=0.2, random_state=0)
  
  # 6. ë¨¸ì‹ ëŸ¬ë‹ í•™ìŠµ ë° í‰ê°€
  from sklearn.ensemble import RandomForestClassifier
  rf = RandomForestClassifier(random_state=0)
  rf.fit(X_train, y_train)
  pred = rf.predict(X_val)
  
  from sklearn.metrics import f1_score
  f1 = f1_score(y_val, pred, average='macro')
  print('f1-macro :', f1)
  
  # 7. ì˜ˆì¸¡ ë° ê²°ê³¼ íŒŒì¼ ìƒì„±
  pred = rf.predict(test)
  submit = pd.DataFrame({'pred':pred})
  submit.to_csv('result1.csv', index=False)
  
  # ì œì¶œ íŒŒì¼ í™•ì¸
  print('\n==== ì œì¶œ íŒŒì¼ (ìƒ˜í”Œ 5ê°œ) ====')
  print(pd.read_csv('result1.csv').head())
```

> ê²°ê³¼
```python
  f1-macro : 0.7020460066061172
  
  ==== ì œì¶œ íŒŒì¼ (ìƒ˜í”Œ 5ê°œ) ====
         pred
  0      Poor
  1      Good
  2  Standard
  3      Good
  4  Standard
```

<br>

---

<BR>

SECTION02 ì•½ë¬¼ ì¢…ë¥˜ ì˜ˆì¸¡
---
- ì£¼ì–´ì§„ ë°ì´í„°ì—ì„œ ì•½ë¬¼ì˜ ì¢…ë¥˜ ì˜ˆì¸¡

  - ì œê³µëœ ë°ì´í„° ëª©ë¡ : drug_train.csv, drug_test.csv
 
  - ì˜ˆì¸¡í•  ì»¬ëŸ¼ : Drug(DrugY, drugX, drugA, drugC, drugB)
 
- í•™ìŠµìš© ë°ì´í„°(train.csv)ì„ ì´ìš©í•´ ì•½ë¬¼ì˜ ì¢…ë¥˜ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ ìƒì„±

- í‰ê°€ìš© ë°ì´í„°(test.csv)ì— ì ìš©í•´ ì–»ì€ ì˜ˆì¸¡ê°’ì„ ì•„ë˜ í˜•ì‹ì˜ csv íŒŒì¼ë¡œ ìƒì„±

  - ì œì¶œ íŒŒì¼ì€ ë‹¤ìŒ 1 ê°œì˜ ì»¬ëŸ¼ í¬í•¨
 
    - pred : ì˜ˆì¸¡ê°’
   
    - ì œì¶œ íŒŒì¼ëª… : 'result2.csv'
   
  - ì œì¶œí•œ ëª¨ë¸ì˜ ì„±ëŠ¥ì€ f1-macro í‰ê°€ì§€í‘œì— ë”°ë¼ ì±„ì 

<BR>

### 01. ë² ì´ìŠ¤ ë¼ì¸
- ë² ì´ìŠ¤ë¼ì¸ì—ì„œ f1 í‰ê°€ ì ìˆ˜ì˜ ê²°ê³¼ê°€ ë†’ê²Œ(1ì— ê°€ê¹ê²Œ) ë‚˜ì˜¬ ê²½ìš°

<br>

#### (1) EDA

> ì½”ë“œ
```python
  # 1. ë¬¸ì œ ì •ì˜
  # í‰ê°€ : f1-macro
  # target : Drug
  # ìµœì¢… íŒŒì¼ : result2.csv(ì»¬ëŸ¼ 1ê°œ pred, 1 í™•ë¥ ê°’)
  
  # 2. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
  import pandas as pd
  
  train = pd.read_csv('./data/drug_train.csv')
  test = pd.read_csv('./data/drug_test.csv')
  
  # 3. íƒìƒ‰ì  ë°ì´í„° ë¶„ì„(EDA)
  print('==== ë°ì´í„° í¬ê¸° ====')
  print('Train Shape :', train.shape)
  print('Test Shape :', test.shape)
  
  print('\n==== ë°ì´í„° ì •ë³´(ìë£Œí˜•) ====')
  print(train.info())
  
  print('\n==== train ê²°ì¸¡ì¹˜ ìˆ˜ ====')
  print(train.isnull().sum())
  
  print('\n==== test ê²°ì¸¡ì¹˜ ìˆ˜ ====')
  print(test.isnull().sum())
  
  print('\n==== train ì¹´í…Œê³ ë¦¬ë³„ ìˆ˜ ===')
  print(train[['Sex', 'BP', 'Cholesterol']].nunique())
  
  print('\n==== test ì¹´í…Œê³ ë¦¬ë³„ ìˆ˜ ====')
  print(test[['Sex', 'BP', 'Cholesterol']].nunique())
  
  print('\n==== target ë¹ˆë„ ====')
  print(train['Drug'].value_counts())
```

> ê²°ê³¼
```python
  ==== ë°ì´í„° í¬ê¸° ====
  Train Shape : (100, 6)
  Test Shape : (100, 5)
  
  ==== ë°ì´í„° ì •ë³´(ìë£Œí˜•) ====
  <class 'pandas.core.frame.DataFrame'>
  RangeIndex: 100 entries, 0 to 99
  Data columns (total 6 columns):
   #   Column       Non-Null Count  Dtype  
  ---  ------       --------------  -----  
   0   Age          100 non-null    int64  
   1   Sex          100 non-null    object 
   2   BP           100 non-null    object 
   3   Cholesterol  100 non-null    object 
   4   Na_to_K      100 non-null    float64
   5   Drug         100 non-null    object 
  dtypes: float64(1), int64(1), object(4)
  memory usage: 4.8+ KB
  None
  
  ==== train ê²°ì¸¡ì¹˜ ìˆ˜ ====
  Age            0
  Sex            0
  BP             0
  Cholesterol    0
  Na_to_K        0
  Drug           0
  dtype: int64
  
  ==== test ê²°ì¸¡ì¹˜ ìˆ˜ ====
  Age            0
  Sex            0
  BP             0
  Cholesterol    0
  Na_to_K        0
  dtype: int64
  
  ==== train ì¹´í…Œê³ ë¦¬ë³„ ìˆ˜ ===
  Sex            2
  BP             3
  Cholesterol    2
  dtype: int64
  
  ==== test ì¹´í…Œê³ ë¦¬ë³„ ìˆ˜ ====
  Sex            2
  BP             3
  Cholesterol    2
  dtype: int64
  
  ==== target ë¹ˆë„ ====
  Drug
  DrugY    41
  drugX    34
  drugA    13
  drugB     8
  drugC     4
  Name: count, dtype: int64
```

<br>

#### (2) ì „ì²˜ë¦¬ ë° ì˜ˆì¸¡
- f1 í‰ê°€ ì ìˆ˜ê°€ ë„ˆë¬´ ë†’ê²Œ ë‚˜ì˜¬ ê²½ìš°(0~1 ì¤‘ì— 1ì ) ì›ì¸

  - ë°ì´í„°ë¥¼ ë‚˜ëˆŒ ë•Œ ë˜ëŠ” ì „ì²˜ë¦¬ ë•Œ ì˜ëª»í•œ ë¶€ë¶„ æœ‰
 
    - model.fit(X, y) ì—ì„œ ëª¨ë¸ í•™ìŠµì‹œ ì‚¬ìš©í•˜ëŠ” X ë°ì´í„°ë¥¼ head() ë¡œ ì¶œë ¥í•´ í™•ì¸
   
    - ê°„í˜¹ target ì´ í•™ìŠµìš© ë°ì´í„° X ì— í¬í•¨ëœ ê²½ìš° ì´ë¯¸ ë‹µì„ ì•Œê³  ìˆê¸°ì— ë§Œì ì´ ë‚˜ì˜´
   
  - ê²€ì¦ ë°ì´í„°ê°€ ë„ˆë¬´ ì‰½ê²Œ ë‚˜ëˆ ì§

    - ì´ë²ˆ ë¬¸ì œì˜ ê²½ìš° í‰ì†ŒëŒ€ë¡œ 20% ê²€ì¦ ë°ì´í„°ë¡œ í‰ê°€í–ˆì„ ë•Œ 1ì  ë‚˜ì˜´
   
      - ê²€ì¦ ë°ì´í„°ë¥¼ í‰ê°€í•˜ëŠ” ë‹¤ë¥¸ ë°©ì‹ í•„ìš”
     
        - í¬ë¡œìŠ¤ ë°¸ë¦¬ë°ì´ì…˜ í™œìš© (í•„ìˆ˜ X)

> ì½”ë“œ
```python
  # 4. ë°ì´í„° ì „ì²˜ë¦¬
  # ì›-í•« ì¸ì½”ë”©
  target = train.pop('Drug')
  
  train = pd.get_dummies(train)
  test = pd.get_dummies(test)
  
  # 5. ê²€ì¦ ë°ì´í„° ë‚˜ëˆ„ê¸°
  from sklearn.model_selection import train_test_split
  X_train, X_val, y_train, y_val = train_test_split(train, target, test_size=0.2, random_state=0)
  
  # 6 ë¨¸ì‹ ëŸ¬ë‹ í•™ìŠµ ë° í‰ê°€
  from sklearn.ensemble import RandomForestClassifier
  rf = RandomForestClassifier(random_state=0)
  rf.fit(X_train, y_train)
  pred = rf.predict(X_val)
  
  from sklearn.metrics import f1_score
  f1 = f1_score(y_val, pred, average='macro')
  print('f1-macro :', f1)
  
  # 7. ì˜ˆì¸¡ ë° ê²°ê³¼ íŒŒì¼ ìƒì„±
  pred = rf.predict(test)
  submit = pd.DataFrame({'pred':pred})
  submit.to_csv('result2.csv', index=False)
  
  # ì œì¶œ íŒŒì¼ í™•ì¸
  print('\n==== ì œì¶œ íŒŒì¼ (ìƒ˜í”Œ 5ê°œ) ====')
  print(pd.read_csv('result2.csv').head())
```

> ê²°ê³¼
```python
  f1-macro : 1.0
  
  ==== ì œì¶œ íŒŒì¼ (ìƒ˜í”Œ 5ê°œ) ====
      pred
  0  DrugY
  1  DrugY
  2  DrugY
  3  DrugY
  4  drugB
```

<br>

#### ğŸ’¡ í¬ë¡œìŠ¤ ë°¸ë¦¬ë°ì´ì…˜(cross-validation)
- ì£¼ì–´ì§„ ë°ì´í„°ì…‹(train)ì„ K ê°œë¡œ ë‚˜ëˆ  ëª¨ë“  ë°ì´í„°ê°€ í•™ìŠµê³¼ ê²€ì¦ ë°ì´í„°ë¡œ í™œìš©ë¨

  - K ë²ˆì˜ í•™ìŠµê³¼ í‰ê°€ë¡œ ì§„í–‰
 
> ì½”ë“œ
```python
  from sklearn.metrics import f1_score
  from sklearn.model_selection import cross_val_score
  
  f1_scores = cross_val_score(rf, train, target, cv=3, scoring='f1_macro')
  print(f1_scores)
  print(f1_scores.mean())
```
- scoring='f1_macro' : í‰ê°€ ì§€í‘œë¡œ f1-macro ì ìˆ˜ë¥¼ ì‚¬ìš©í•˜ê² ë‹¤ëŠ” ëœ»

  - ê° í´ë˜ìŠ¤ë³„ F1 ì ìˆ˜ë¥¼ ê³„ì‚°í•œ í›„, í´ë˜ìŠ¤ ê°„ì˜ ë¶ˆê· í˜•ì„ ê³ ë ¤í•´ í‰ê· ì„ ë‚´ë©° í´ë˜ìŠ¤ ë¹„ìœ¨ì´ ë¶ˆê· í˜•í•œ ë¬¸ì œì—ì„œ íš¨ê³¼ì 

> ê²°ê³¼
```python
  [1.         0.93777778 0.78461538]
  0.9074643874643874
```
- cv = 3 ìœ¼ë¡œ ì„¤ì • : 3ë²ˆì˜ í•™ìŠµê³¼ í‰ê°€ê°€ ì§„í–‰ë¨

  - ê°ê° [1. 0.93777778 0.78461538] ê²°ê³¼ê°€ ë‚˜ì˜´
 
    - 0.78 ìˆëŠ” ê²ƒìœ¼ë¡œ ë³´ì•„ ë² ì´ìŠ¤ë¼ì¸ì—ì„œ ë°ì´í„°ë¥¼ ë‚˜ëˆŒ ë•Œ ìš´ ì¢‹ê²Œ ì‰¬ìš´ ë°ì´í„°ë¡œë§Œ ê²€ì¦ë°ì´í„°ê°€ ë‚˜ëˆ ì¡Œì„ ê°€ëŠ¥ì„± æœ‰
   
    - 3ê°œì˜ ê²°ê³¼ë¥¼ í‰ê· í•˜ë©´ 0.9ì 

<br>

#### ğŸ’¡ scoring íŒŒë¼ë¯¸í„°
- í‰ê°€ ê¸°ì¤€ì„ ì§€ì •í•˜ë©°, ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë‹¤ì–‘í•œ ë°©ì‹ìœ¼ë¡œ ì¸¡ì •í•  ìˆ˜ ìˆë„ë¡ ì—¬ëŸ¬ í‰ê°€ì§€í‘œë¥¼ ì§€ì›

  - ë¶„ë¥˜, íšŒê·€ ë“± ë‹¤ì–‘í•œ ë¬¸ì œ ìœ í˜•ì— ë§ëŠ” ì„±ëŠ¥ í‰ê°€ê°€ ê°€ëŠ¥

<br>

(1) ë¶„ë¥˜ í‰ê°€ ì§€í‘œ
- accuracy: ì •í™•ë„. ì „ì²´ ìƒ˜í”Œ ì¤‘ì—ì„œ ì •í™•íˆ ì˜ˆì¸¡í•œ ë¹„ìœ¨

- f1: F1 ì ìˆ˜. ì •ë°€ë„ì™€ ì¬í˜„ìœ¨ì˜ ì¡°í™” í‰ê· , ë¶ˆê· í˜• ë°ì´í„°ì…‹ì—ì„œ ìœ ìš©

- f1_macro: í´ë˜ìŠ¤ë³„ F1 ì ìˆ˜ë¥¼ ê³„ì‚°í•œ í›„, ì´ë¥¼ í‰ê· í•˜ì—¬ ê³„ì‚°. í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¬¸ì œì—ì„œ ì„±ëŠ¥ì„ ê· í˜• ìˆê²Œ í‰ê°€

- f1_micro: í´ë˜ìŠ¤ë³„ ì˜ˆì¸¡ì„ ì „ë¶€ í•©ì‚°í•˜ì—¬ F1 ì ìˆ˜ë¥¼ ê³„ì‚°. í´ë˜ìŠ¤ ë¹ˆë„ì— ë”°ë¥¸ ê°€ì¤‘ í‰ê· ì´ ë°˜ì˜ë¨

- f1_weighted: í´ë˜ìŠ¤ë³„ F1 ì ìˆ˜ë¥¼ ê³„ì‚°í•œ í›„ ê° í´ë˜ìŠ¤ì˜ ìƒ˜í”Œ ìˆ˜ë¥¼ ê°€ì¤‘ì¹˜ë¡œ ë°˜ì˜í•´ í‰ê· 

- precision: ì •ë°€ë„. ì–‘ì„±ìœ¼ë¡œ ì˜ˆì¸¡ëœ ìƒ˜í”Œ ì¤‘ ì‹¤ì œë¡œ ì–‘ì„±ì¸ ìƒ˜í”Œì˜ ë¹„ìœ¨

- recall: ì¬í˜„ìœ¨. ì‹¤ì œ ì–‘ì„± ìƒ˜í”Œ ì¤‘ì—ì„œ ì–‘ì„±ìœ¼ë¡œ ì •í™•íˆ ì˜ˆì¸¡í•œ ë¹„ìœ¨

- roc_auc: ROC ê³¡ì„  ì•„ë˜ì˜ ë©´ì . ì´ì§„ ë¶„ë¥˜ ë¬¸ì œì—ì„œ í´ë˜ìŠ¤ êµ¬ë¶„ ëŠ¥ë ¥ì„ ì¸¡ì •

- log_loss: ë¡œê·¸ ì†ì‹¤. ì˜ˆì¸¡ í™•ë¥ ê³¼ ì‹¤ì œ í´ë˜ìŠ¤ ê°„ì˜ ì†ì‹¤ì„ ì¸¡ì •

<br>

(2) íšŒê·€ í‰ê°€ ì§€í‘œ
- r2: ê²°ì • ê³„ìˆ˜. ì˜ˆì¸¡ ê°’ì´ ì‹¤ì œ ê°’ì„ ì–¼ë§ˆë‚˜ ì˜ ì„¤ëª…í•˜ëŠ”ì§€ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì§€í‘œ

- neg_mean_absolute_error: í‰ê·  ì ˆëŒ€ ì˜¤ì°¨. ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ì˜ ì°¨ì´ë¥¼ ì ˆëŒ€ê°’ìœ¼ë¡œ ê³„ì‚°í•˜ì—¬ í‰ê· 

- neg_mean_squared_error: í‰ê·  ì œê³± ì˜¤ì°¨. ì˜¤ì°¨ë¥¼ ì œê³±í•˜ì—¬ í‰ê· í•œ ê°’, í° ì˜¤ì°¨ì— í° íŒ¨ë„í‹°ë¥¼ ë¶€ê³¼

- neg_root_mean_squared_error: í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨. í‰ê·  ì œê³± ì˜¤ì°¨ì˜ ì œê³±ê·¼, ì˜ˆì¸¡ê°’ì˜ í‘œì¤€ í¸ì°¨ì™€ ìœ ì‚¬í•œ í•´ì„

- explained_variance: ì˜ˆì¸¡ê°’ì´ ì‹¤ì œ ë°ì´í„°ì˜ ë¶„ì‚°ì„ ì„¤ëª…í•˜ëŠ” ë¹„ìœ¨

<br>

(3) ë‹¤ì¤‘ ë¶„ë¥˜ í‰ê°€ ì§€í‘œ
- balanced_accuracy: ê° í´ë˜ìŠ¤ë³„ë¡œ ì •í™•ë„ë¥¼ ê³„ì‚°í•˜ì—¬ í‰ê· 

- top_k_accuracy: kê°œì˜ ìƒìœ„ ì˜ˆì¸¡ ì¤‘ ì •ë‹µì´ í¬í•¨ëœ ë¹„ìœ¨(ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜)

- jaccard: ì˜ˆì¸¡ ê°’ê³¼ ì‹¤ì œ ê°’ ì‚¬ì´ì˜ ìœ ì‚¬ì„±ì„ ì¸¡ì •í•˜ëŠ” Jaccard ê³„ìˆ˜

<br>

### 02. ì„±ëŠ¥ ê°œì„ 
- ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ ì ìˆ˜ì™€ ì„±ëŠ¥ ê°œì„  ëª¨ë¸ ì ìˆ˜ ë¹„êµ

- ë°ì´í„° ì „ì²˜ë¦¬

  - ë ˆì´ë¸” ì¸ì½”ë”©
 
  - ìŠ¤ì¼€ì¼ : Standard Encoder, Min-Max Encoder, Robust Encoder
 
- í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹

  - max_depth : 3 ~ 7
 
  - n_estimators : 200 ~ 500

<br>

|ë°ì´í„° ì „ì²˜ë¦¬/í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹|f1|ì œì¶œ|
|-|-|-|
|ë² ì´ìŠ¤ë¼ì¸|0.9074643874643874|ì„ íƒ / 1ì°¨ ì œì¶œ, 2ì°¨ ì œì¶œ|
|ë ˆì´ë¸” ì¸ì½”ë”©|0.8815384615384616||
|ìŠ¤ì¼€ì¼ë§(Standard, Min-Max, Robust Encoder)|0.9074643874643874||
|max_depth = 3|0.7230140873619134||
|max_depth = 5, 7|0.9074643874643874||
|n_estimators = 200, 400, 500|0.9074643874643874||

<br>

> ì½”ë“œ
```python
  # 2. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
  import pandas as pd
  
  train = pd.read_csv('./data/drug_train.csv')
  test = pd.read_csv('./data/drug_test.csv')
  
  # 4. ë°ì´í„° ì „ì²˜ë¦¬
  target = train.pop('Drug')
  
  # ìŠ¤ì¼€ì¼ë§ (ì˜í–¥ X, ìƒëµ)
  # from sklearn.preprocessing import RobustScaler
  # scaler = RobustScaler()
  # train['Age'] = scaler.fit_transform(train[['Age']])
  # test['Age'] = scaler.transform(test[['Age']])
  
  # ì›-í•« ì¸ì½”ë”©(Drug ì»¬ëŸ¼ ì œì™¸)
  train = pd.get_dummies(train)
  test = pd.get_dummies(test)
  
  # ë ˆì´ë¸” ì¸ì½”ë”©(Drug ì»¬ëŸ¼ ì œì™¸)
  # from sklearn.preprocessing import LabelEncoder
  # cols = train.select_dtypes(include='object').columns
  # for col in cols:
  #     le = LabelEncoder()
  #     train[col] = le.fit_transform(train[col])
  #     test[col] = le.transform(test[col])
  
  # 5. í¬ë¡œìŠ¤ ë°¸ë¦¬ë°ì´ì…˜(cross-validation)
  from sklearn.metrics import f1_score
  from sklearn.model_selection import cross_val_score
  from sklearn.ensemble import RandomForestClassifier
  
  rf = RandomForestClassifier(random_state=0)
  f1_scores = cross_val_score(rf, train, target, cv=3, scoring='f1_macro')
  print(f1_scores.mean())
  
  # 6. ë¨¸ì‹ ëŸ¬ë‹ í•™ìŠµ
  rf.fit(train, target)
  
  # 7. ì˜ˆì¸¡ ë° ê²°ê³¼ íŒŒì¼ ìƒì„±
  pred = rf.predict(test)
  submit = pd.DataFrame({'pred':pred})
  submit.to_csv('result2.csv', index=False)
```
- í¬ë¡œìŠ¤ë°¸ë¦¬ë°ì´ì…˜ ì‚¬ìš©ì‹œ train_test_split() í•„ìš” X

  - í¬ë¡œìŠ¤ë°¸ë¦¬ë°ì´ì…˜ìœ¼ë¡œ ì ìˆ˜ í™•ì¸ í›„ train ì „ì²´ ë°ì´í„° ì‚¬ìš©í•´ ëª¨ë¸ í•™ìŠµ

> ê²°ê³¼
```python
  0.9074643874643874
```

<br>

#### ğŸ’¡ ë°ì´í„°í”„ë ˆì„ì—ì„œ ëŒ€ê´„í˜¸ ìˆ˜
- ë°ì´í„°í”„ë ˆì„ì—ì„œ ì»¬ëŸ¼ ì„ íƒ ì‹œ ëŒ€ê´„í˜¸ ì‚¬ìš©í•˜ëŠ” ë°©ë²•

  - ëŒ€ê´„í˜¸ê°€ 1ê°œì¸ ê²½ìš° : train['Age']
 
    - ì„ íƒí•œ ì»¬ëŸ¼ì„ ì‹œë¦¬ì¦ˆ(Series) í˜•íƒœë¡œ ë°˜í™˜
   
  - ëŒ€ê´„í˜¸ê°€ 2ê°œì¸ ê²½ìš° : train[['Age']]
 
    - ì„ íƒí•œ ì»¬ëŸ¼ì„ ë°ì´í„°í”„ë ˆì„(DataFrame) í˜•íƒœë¡œ ë°˜í™˜
   
- ìŠ¤ì¼€ì¼ë§ ë“± ì „ì²˜ë¦¬ í•¨ìˆ˜ë“¤ì€ ì¼ë°˜ì ìœ¼ë¡œ ë°ì´í„°í”„ë ˆì„ ìë£Œí˜• ì…ë ¥

  - ëŒ€ê´„í˜¸ 2ê°œ ì‚¬ìš©í•´ ë°ì´í„°í”„ë ˆì„ í˜•íƒœë¡œ ë°ì´í„° ë„˜ê²¨ì£¼ê¸°
 
- ì—¬ëŸ¬ ì»¬ëŸ¼ ì„ íƒ í•  ë•Œ ëŒ€ê´„í˜¸ 2ê°œ ì‚¬ìš©

  -  train[['ì»¬ëŸ¼ëª…1', 'ì»¬ëŸ¼ëª…2']]
 
  - ì¼ë°˜ì ìœ¼ë¡œ ì—¬ëŸ¬ ì»¬ëŸ¼ì¸ ê²½ìš° cols = ['ì»¬ëŸ¼ëª…1', 'ì»¬ëŸ¼ëª…2'] ì²˜ëŸ¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“  í›„ train[cols] ì— ì ìš©
  
    - ëŒ€ê´„í˜¸ê°€ 1ê°œì²˜ëŸ¼ ë³´ì˜€ì„ ë¿

<br>

---

<BR>

SECTION03 ìœ ë¦¬ ì¢…ë¥˜ ì˜ˆì¸¡
---
- ìœ ë¦¬ ì‹ë³„ë°ì´í„°ì—ì„œ ìœ ë¦¬ì˜ ì¢…ë¥˜ ì˜ˆì¸¡

  - ì œê³µëœ ë°ì´í„° ëª©ë¡ : glass_train.csv, glass_test.csv
 
  - ì˜ˆì¸¡í•  ì»¬ëŸ¼ : Type(1, 2, 3, 5, 6, 7)
 
- í•™ìŠµìš© ë°ì´í„°(train.csv)ë¥¼ ì´ìš©í•´ ì•½ë¬¼ ì¢…ë¥˜ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ ìƒì„±

- í‰ê°€ìš© ë°ì´í„°(test.csv)ì— ì ìš©í•´ ì–»ì€ ì˜ˆì¸¡ê°’ì„ ì•„ë˜ì™€ ê°™ì€ í˜•ì‹ì˜ csv íŒŒì¼ë¡œ ìƒì„±

  - ì œì¶œ íŒŒì¼ì€ ë‹¤ìŒ 1ê°œì˜ ì»¬ëŸ¼ í¬í•¨
 
    - pred : ì˜ˆì¸¡ê°’
   
    - ì œì¶œ íŒŒì¼ëª… : 'result3.csv'
   
  - ì œì¶œí•œ ëª¨ë¸ì˜ ì„±ëŠ¥ì€ f1-weighted í‰ê°€ì§€í‘œì— ë”°ë¼ ì±„ì 
 
<br>

### 01. ë² ì´ìŠ¤ë¼ì¸
- ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ê³ , ê°„ë‹¨í•œ íƒìƒ‰ì  ë°ì´í„° ë¶„ì„ ì§„í–‰

<br>

#### (1) EDA
> ì½”ë“œ
```python
  # 1. ë¬¸ì œ ì •ì˜
  # í‰ê°€ : f1-weighted
  # target : Type
  # ìµœì¢… íŒŒì¼ : result3.csv
  
  # 2. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
  import pandas as pd
  
  train = pd.read_csv('./data/glass_train.csv')
  test = pd.read_csv('./data/glass_test.csv')
  
  # 3. íƒìƒ‰ì  ë°ì´í„° ë¶„ì„ (EDA)
  print('==== ë°ì´í„° í¬ê¸° ====')
  print('Train Shape :', train.shape )
  print('Test Shape :', test.shape)
  
  print('\n==== train ë°ì´í„° ìƒ˜í”Œ ====')
  print(train.head())
  
  print('\n==== test ë°ì´í„° ìƒ˜í”Œ ====')
  print(test.head())
  
  print('\n==== ë°ì´í„° ì •ë³´(ìë£Œí˜•) ====')
  print(train.info())
  
  print('\n==== train ê²°ì¸¡ì¹˜ ìˆ˜ ====')
  print(train.isnull().sum())
  
  print('\n==== test ê²°ì¸¡ì¹˜ ìˆ˜ ====')
  print(train.isnull().sum())
  
  print('\n==== target ë¹ˆë„ ====')
  print(train['Type'].value_counts())
```

> ê²°ê³¼
```python
  ==== ë°ì´í„° í¬ê¸° ====
  Train Shape : (149, 10)
  Test Shape : (65, 9)
  
  ==== train ë°ì´í„° ìƒ˜í”Œ ====
          RI     Na    Mg    Al     Si     K    Ca   Ba    Fe  Type
  0  1.51829  14.46  2.24  1.62  72.38  0.00  9.26  0.0  0.00     6
  1  1.51610  13.33  3.53  1.34  72.67  0.56  8.33  0.0  0.00     3
  2  1.52172  13.48  3.74  0.90  72.01  0.18  9.61  0.0  0.07     1
  3  1.51905  13.60  3.62  1.11  72.64  0.14  8.76  0.0  0.00     1
  4  1.51631  13.34  3.57  1.57  72.87  0.61  7.89  0.0  0.00     2
  
  ==== test ë°ì´í„° ìƒ˜í”Œ ====
          RI     Na    Mg    Al     Si     K     Ca    Ba    Fe
  0  1.51748  12.86  3.56  1.27  73.21  0.54   8.38  0.00  0.17
  1  1.52058  12.85  1.61  2.17  72.18  0.76   9.70  0.24  0.51
  2  1.52475  11.45  0.00  1.88  72.19  0.81  13.24  0.00  0.34
  3  1.51690  13.33  3.54  1.61  72.54  0.68   8.11  0.00  0.00
  4  1.52177  13.75  1.01  1.36  72.19  0.33  11.14  0.00  0.00
  
  ==== ë°ì´í„° ì •ë³´(ìë£Œí˜•) ====
  <class 'pandas.core.frame.DataFrame'>
  RangeIndex: 149 entries, 0 to 148
  Data columns (total 10 columns):
   #   Column  Non-Null Count  Dtype  
  ---  ------  --------------  -----  
   0   RI      149 non-null    float64
   1   Na      149 non-null    float64
   2   Mg      149 non-null    float64
   3   Al      149 non-null    float64
   4   Si      149 non-null    float64
   5   K       149 non-null    float64
   6   Ca      149 non-null    float64
   7   Ba      149 non-null    float64
   8   Fe      149 non-null    float64
   9   Type    149 non-null    int64  
  dtypes: float64(9), int64(1)
  memory usage: 11.8 KB
  None
  
  ==== train ê²°ì¸¡ì¹˜ ìˆ˜ ====
  RI      0
  Na      0
  Mg      0
  Al      0
  Si      0
  K       0
  Ca      0
  Ba      0
  Fe      0
  Type    0
  dtype: int64
  
  ==== test ê²°ì¸¡ì¹˜ ìˆ˜ ====
  RI      0
  Na      0
  Mg      0
  Al      0
  Si      0
  K       0
  Ca      0
  Ba      0
  Fe      0
  Type    0
  dtype: int64
  
  ==== target ë¹ˆë„ ====
  Type
  2    53
  1    49
  7    23
  3     9
  5     8
  6     7
  Name: count, dtype: int64
```
- ë°ì´í„° ìë£Œí˜•ì´ ëª¨ë‘ ìˆ˜ì¹˜í˜• ë°ì´í„°

  - ë³„ë„ ì „ì²˜ë¦¬ ì—†ì´ ë² ì´ìŠ¤ë¼ì¸ êµ¬ì¶•

- ê²°ì¸¡ì¹˜ ì—†ìŒ

- target ì€ 6ê°€ì§€

<br>

#### (2) ì „ì²˜ë¦¬ ë° ì˜ˆì¸¡

> ì½”ë“œ
```python
  # 4. ë°ì´í„° ì „ì²˜ë¦¬
  target = train.pop('Type')
  
  # 5. ê²€ì¦ ë°ì´í„° ë‚˜ëˆ„ê¸°
  from sklearn.model_selection import train_test_split
  X_train, X_val, y_train, y_val = train_test_split(train, target, test_size=0.2, random_state=0)
  
  # 6. ë¨¸ì‹ ëŸ¬ë‹ í•™ìŠµ ë° í‰ê°€
  from sklearn.ensemble import RandomForestClassifier
  rf = RandomForestClassifier(random_state=0)
  rf.fit(X_train, y_train)
  pred = rf.predict(X_val)
  
  from sklearn.metrics import f1_score
  f1 = f1_score(y_val, pred, average='weighted')
  print('f1 :', f1)
  
  # 7. ì˜ˆì¸¡ ë° ê²°ê³¼ íŒŒì¼ ìƒì„±
  pred = rf.predict(test)
  submit = pd.DataFrame({'pred':pred})
  submit.to_csv('result3.csv', index=False)
  
  print('\n==== ì œì¶œ íŒŒì¼ (ìƒ˜í”Œ 5ê°œ) ====')
  print(pd.read_csv('result3.csv').head())
```

> ê²°ê³¼
```python
  f1 : 0.6119801766860591
  
  ==== ì œì¶œ íŒŒì¼ (ìƒ˜í”Œ 5ê°œ) ====
     pred
  0     1
  1     2
  2     2
  3     2
  4     2
```

<br>

### 02. ì„±ëŠ¥ ê°œì„ 
- ëœë¤í¬ë ˆìŠ¤ëŠ” ì—¬ëŸ¬ ê°œì˜ ì˜ì‚¬ê²°ì • ë‚˜ë¬´ë¡œ ì´ë£¨ì–´ì§„ ì•™ìƒë¸” ëª¨ë¸

  - íŠ¸ë¦¬ ê¸°ë°˜ ëª¨ë¸ì€ í”¼ì²˜ì˜ ëŒ€ì†Œ ê´€ê³„ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ í•™ìŠµí•˜ê¸° ë•Œë¬¸ì— ìŠ¤ì¼€ì¼ë§ì— í¬ê²Œ ë¯¼ê°í•˜ì§€ ì•ŠìŒ
 
- n_estimators ì„¤ì •ìœ¼ë¡œ ì„±ëŠ¥ì— í¬ê²Œ ë³€í™”ê°€ ìˆì„ ë•Œ ê°™ì€ ê²°ê³¼ë¼ë©´ ë‚®ì€ ì„¤ì • ì„ íƒ

  - n_setimators ê°’ì´ í¬ë©´ íŠ¸ë¦¬ì˜ ìˆ˜ê°€ ë§ì•„ì ¸ ì—°ì‚° ì†ë„ê°€ ëŠë ¤ì§
 
- ë°ì´í„° ì „ì²˜ë¦¬

  - ìŠ¤ì¼€ì¼ë§ : ì„±ëŠ¥ ë³€í™” X
 
- í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹

  - max_depth : 5, 7, 10
 
  - n_estimators : 200, 500

<BR>

|ë°ì´í„° ì „ì²˜ë¦¬/í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹|f1|ì œì¶œ|
|-|-|-|
|ë² ì´ìŠ¤ë¼ì¸|0.6119801766860591|ì„ íƒ / 1ì°¨ ì œì¶œ|
|ìŠ¤ì¼€ì¼ë§(Standard, Min-Max, Robust)|0.6119801766860591||
|max_depth = 5|0.6410714285714286|ì„ íƒ|
|max_depth = 7|0.6119801766860591||
|max_depth = 10|0.6119801766860591||
|max_depth = 5, n_estimators = 200|0.6507936507936507|ì„ íƒ / 2ì°¨ ì œì¶œ|
|max_depth = 5, n_estimators = 500|0.6507936507936507||

<br>

> ì½”ë“œ
```python
  # 2. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
  import pandas as pd
  
  train = pd.read_csv('./data/glass_train.csv')
  test =pd.read_csv('./data/glass_test.csv')
  
  # 4. ë°ì´í„° ì „ì²˜ë¦¬
  target = train.pop('Type')
  
  # ìŠ¤ì¼€ì¼ë§ (íš¨ê³¼ X)
  # from sklearn.preprocessing import StandardScaler
  # scaler = StandardScaler()
  # cols = train.columns
  # train[cols] = scaler.fit_transform(train[cols])
  # test[cols] = scaler.transform(test[cols])
  
  # 5. ê²€ì¦ ë°ì´í„° ë‚˜ëˆ„ê¸°
  from sklearn.model_selection import train_test_split
  X_train, X_val, y_train, y_val = train_test_split(train, target, test_size=0.2, random_state=0)
  
  # 6. ë¨¸ì‹ ëŸ¬ë‹ í•™ìŠµ ë° í‰ê°€
  from sklearn.ensemble import RandomForestClassifier
  rf = RandomForestClassifier(max_depth=5, n_estimators=200, random_state=0)
  rf.fit(X_train, y_train)
  pred = rf.predict(X_val)
  
  from sklearn.metrics import f1_score
  f1 = f1_score(y_val, pred, average='weighted')
  print('f1 :', f1)
  
  # 7. ì˜ˆì¸¡ ë° ê²°ê³¼ íŒŒì¼ ìƒì„±
  pred = rf.predict(test)
  submit = pd.DataFrame({'pred':pred})
  submit.to_csv('result3.csv', index=False)
  
  print('\n==== ì œì¶œ íŒŒì¼ (ìƒ˜í”Œ 5ê°œ) ====')
  print(pd.read_csv('result3.csv').head())
```

> ê²°ê³¼
```python
  f1 : 0.6507936507936507
  
  ==== ì œì¶œ íŒŒì¼ (ìƒ˜í”Œ 5ê°œ) ====
     pred
  0     1
  1     5
  2     5
  3     2
  4     2
```

<br>









