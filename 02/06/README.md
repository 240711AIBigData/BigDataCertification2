# CHAPTER06 ì´ì§„ ë¶„ë¥˜ ì—°ìŠµë¬¸ì œ
- ì²« ë²ˆì§¸ ë² ì´ìŠ¤ë¼ì¸ì„ ë§Œë“¤ ë•ŒëŠ” ë¨¸ì‹ ëŸ¬ë‹ í”„ë¡œì„¸ìŠ¤ëŒ€ë¡œ

- ëœë¤í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ ì‚¬ìš©

<br>

SECTION01 í™˜ìì˜ ë‹¹ë‡¨ë³‘ ì—¬ë¶€ ì˜ˆì¸¡
---
- í™˜ìì˜ ë‹¹ë‡¨ë³‘ ì—¬ë¶€ ì˜ˆì¸¡

  - ì œê³µëœ ë°ì´í„° ëª©ë£ : diabetes_train.csv, diabetes_test.csv
 
  - ì˜ˆì¸¡í•  ì»¬ëŸ¼ : Outcome(0: ì •ìƒ, 1: ë‹¹ë‡¨ë³‘)

- í•™ìŠµìš© ë°ì´í„°(train)ë¥¼ ì´ìš©í•´ í™˜ìì˜ ë‹¹ë‡¨ë³‘ì„ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ ìƒì„±

- í‰ê°€ìš© ë°ì´í„°(test)ì— ì ìš©í•´ ì–»ì€ ì˜ˆì¸¡ê°’ì€ ì•„ë˜ í˜•ì‹ì˜ csv íŒŒì¼ë¡œ ìƒì„±

  - ì œì¶œ íŒŒì¼ì€ ë‹¤ìŒ 1ê°œì˜ ì»¬ëŸ¼ì„ í¬í•¨í•´ì•¼ í•¨
 
    - pred : ì˜ˆì¸¡ê°’(ë‹¹ë‡¨ë³‘ì¼ í™•ë¥ )
   
    - ì œì¶œ íŒŒì¼ëª… : 'result1.csv'
   
  - ì œì¶œí•œ ëª¨ë¸ì˜ ì„±ëŠ¥ì€ ROC-AUC í‰ê°€ì§€í‘œì— ë”°ë¼ ì±„ì 

<br>

### 01. ë² ì´ìŠ¤ë¼ì¸
- ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ê³ , ê°„ë‹¨í•œ íƒìƒ‰ì  ë°ì´í„° ë¶„ì„ ì§„í–‰

> ì½”ë“œ
```python
  # 1. ë¬¸ì œ ì •ì˜
  # í‰ê°€ : roc-auc
  # target : Outcome
  # ìµœì¢… íŒŒì¼ : result.csv (ì»¬ëŸ¼ 1ê°œ pred, 1 í™•ë¥ ê°’)
  
  # 2. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
  import pandas as pd
  
  train = pd.read_csv('./data/diabetes_train.csv')
  test = pd.read_csv('./data/diabetes_test.csv')
  
  # 3. íƒìƒ‰ì  ë°ì´í„° ë¶„ì„(EDA)
  print('==== ë°ì´í„° í¬ê¸° ====')
  print('Train Shape :', train.shape)
  print('Test Shape :', test.shape)
  print('\n')     # ì¤„ë°”ê¿ˆ
  
  print('==== train ë°ì´í„° ìƒ˜í”Œ ====')
  print(train.head(1))
  print('\n')
  
  print('==== test ë°ì´í„° ìƒ˜í”Œ ====')
  print(test.head(1))
  print('\n')
  
  print('==== ë°ì´í„° ì •ë³´(ìë£Œí˜•) ====')
  print(train.info())
  print('\n')
  
  print('==== train ê²°ì¸¡ì¹˜ ìˆ˜ ====')
  print(train.isnull().sum().sum())
  print('\n')
  
  print('==== test ê²°ì¸¡ì¹˜ ìˆ˜ ====')
  print(test.isnull().sum().sum())
  print('\n')
  
  print('==== target ë¹ˆë„ ====')
  print(train['Outcome'].value_counts())
```

> ê²°ê³¼
```python
  ==== ë°ì´í„° í¬ê¸° ====
  Train Shape : (614, 9)
  Test Shape : (154, 8)
  
  
  ==== train ë°ì´í„° ìƒ˜í”Œ ====
     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \
  0            1      118             58             36       94  33.3   
  
     DiabetesPedigreeFunction  Age  Outcome  
  0                     0.261   23        0  
  
  
  ==== test ë°ì´í„° ìƒ˜í”Œ ====
     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \
  0            3      102             74              0        0  29.5   
  
     DiabetesPedigreeFunction  Age  
  0                     0.121   32  
  
  
  ==== ë°ì´í„° ì •ë³´(ìë£Œí˜•) ====
  <class 'pandas.core.frame.DataFrame'>
  RangeIndex: 614 entries, 0 to 613
  Data columns (total 9 columns):
   #   Column                    Non-Null Count  Dtype  
  ---  ------                    --------------  -----  
   0   Pregnancies               614 non-null    int64  
   1   Glucose                   614 non-null    int64  
   2   BloodPressure             614 non-null    int64  
   3   SkinThickness             614 non-null    int64  
   4   Insulin                   614 non-null    int64  
   5   BMI                       614 non-null    float64
   6   DiabetesPedigreeFunction  614 non-null    float64
   7   Age                       614 non-null    int64  
   8   Outcome                   614 non-null    int64  
  dtypes: float64(2), int64(7)
  memory usage: 43.3 KB
  None
  
  
  ==== train ê²°ì¸¡ì¹˜ ìˆ˜ ====
  0
  
  
  ==== test ê²°ì¸¡ì¹˜ ìˆ˜ ====
  0
  
  
  ==== target ë¹ˆë„ ====
  Outcome
  0    403
  1    211
  Name: count, dtype: int64
```
- ì£¼ì–´ì§„ ë°ì´í„°ëŠ” ê²°ì¸¡ì¹˜ê°€ ì—†ê³  ëª¨ë‘ ìˆ˜ì¹˜í˜•

  - ë² ì´ìŠ¤ë¼ì¸ì—ì„œëŠ” ì „ì²˜ë¦¬ ìƒëµ

<br>

> ì½”ë“œ
```python
  # 4. ë°ì´í„° ì „ì²˜ë¦¬
  target = train.pop('Outcome')    # ë³€ìˆ˜ ë¶„ë¦¬
  
  # 5. ê²€ì¦ ë°ì´í„° ë‚˜ëˆ„ê¸°
  from sklearn.model_selection import train_test_split
  X_train, X_val, y_train, y_val = train_test_split(train, target, test_size=0.2, random_state=0)
  
  print('\n ==== ë¶„í• ëœ ë°ì´í„° í¬ê¸° ====')
  print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)
  
  # 6. ë¨¸ì‹ ëŸ¬ë‹ í•™ìŠµ ë° í‰ê°€
  from sklearn.ensemble import RandomForestClassifier
  rf = RandomForestClassifier(random_state=0)
  rf.fit(X_train, y_train)
  pred = rf.predict_proba(X_val)
  
  print('\n ==== ì˜ˆì¸¡ ê²°ê³¼ í™•ì¸ (ìƒ˜í”Œ 5ê°œ) ====')
  print(pred[:5])
  
  from sklearn.metrics import roc_auc_score
  roc_auc = roc_auc_score(y_val, pred[:, 1])
  print('\n roc_auc :', roc_auc)
  
  # 7. ì˜ˆì¸¡ ë° ê²°ê³¼ íŒŒì¼ ìƒì„±
  pred = rf.predict_proba(test)
  submit = pd.DataFrame({'pred':pred[:, 1]})
  submit.to_csv('result1.csv', index=False)
  
  # ì œì¶œ íŒŒì¼ í™•ì¸
  print('\n ==== ì œì¶œ íŒŒì¼(ìƒ˜í”Œ 5ê°œ) ====')
  print(pd.read_csv('result1.csv').head())
```
- ê²€ì¦ ë°ì´í„°ë¥¼ í•™ìŠµìš©(train) ë°ì´í„°ì—ì„œ 20% ì •ë„ ì‚¬ìš©

- ë°ì´í„° ë¶„í•  ì „ target ë¶„ë¦¬í•˜ì§€ ì•ŠëŠ”ë‹¤ë©´
```python
  X_train, X_val, y_train, y_val = train_test_split(train.drop('target', axis=1), train['target'], test_size=0.2, random_state=0)
```

- ëœë¤í¬ë ˆìŠ¤íŠ¸ë¡œ ëª¨ë¸ì„ ë§Œë“¤ê³  ì˜ˆì¸¡í•œ ê²°ê³¼ ROC-AUC ê°€ 0.80

- ì‹œí—˜ì—ì„œëŠ” pd.read_csv('result.csv') ë¡œ ìƒì„±ëœ csv í™•ì¸ í›„ ë² ì´ìŠ¤ë¼ì¸ì„ 1ì°¨ ì œì¶œ

> ê²°ê³¼
```python
   ==== ë¶„í• ëœ ë°ì´í„° í¬ê¸° ====
  (491, 8) (123, 8) (491,) (123,)
  
   ==== ì˜ˆì¸¡ ê²°ê³¼ í™•ì¸ (ìƒ˜í”Œ 5ê°œ) ====
  [[0.88 0.12]
   [0.29 0.71]
   [0.41 0.59]
   [0.75 0.25]
   [0.89 0.11]]
  
   roc_auc : 0.8002739726027398
  
   ==== ì œì¶œ íŒŒì¼(ìƒ˜í”Œ 5ê°œ) ====
     pred
  0  0.17
  1  0.33
  2  0.11
  3  0.04
  4  0.09
```

<br>

### 02. ì„±ëŠ¥ ê°œì„ 
- ë² ì´ìŠ¤ë¼ì¸ì„ ë„ì›€ ì—†ì´ ë§Œë“¤ ìˆ˜ ìˆì„ ë•Œë¶€í„° ì‹œì‘

- ì„±ëŠ¥ ê°œì„ ì˜ ëª©ì ì€ ë² ì´ìŠ¤ë¼ì¸ë³´ë‹¤ ì¢‹ì€ ê²°ê³¼ ì–»ê¸°

- ì„±ëŠ¥ ê°œì„  ê¸°ì¤€

  - ì„±ëŠ¥ì´ ë² ì´ìŠ¤ë¼ì¸ë³´ë‹¤ ì˜¬ë¼ê°€ë©´ ì ìš©
 
  - ìˆ˜ì •ëœ ë§ˆì§€ë§‰ ì ìˆ˜ë³´ë‹¤ ë‚´ë ¤ê°€ë©´ ì ìš© X

- ì„±ëŠ¥ ê°œì„  ë°©ë²• ë° ìˆœì„œ

  - ì „ì²˜ë¦¬ â†’ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ : ë°ì´í„°ê°€ ë‹¬ë¼ì§€ë©´ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ë„ ë‹¤ì‹œ í•´ì•¼í•˜ê¸° ë•Œë¬¸
 
    - ë°ì´í„° ì „ì²˜ë¦¬
   
      - ëª¨ë‘ ìˆ˜ì¹˜í˜• ë°ì´í„°ë¯€ë¡œ ìŠ¤ì¼€ì¼ë§ ì„¸ ê°€ì§€ ì ìš©
     
      - Min-Max-Scaler ì ìš©ê°’ì´ ê°€ì¥ ë†’ìŒ
   
    - í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
   
      - ëœë¤í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ì—ì„œ í•˜ì´í¼íŒŒë¼ë¯¸í„°ëŠ” max_depth ì™€ n_estimators
     
        - max_depth : íŠ¸ë¦¬ì˜ ìµœëŒ€ ê¹Šì´
       
          - íŠ¸ë¦¬ì˜ ê¹Šì´ ì œí•œ â†’ ê³¼ì í•© ë°©ì§€
         
          - ê¸°ë³¸ê°’ ì—†ìŒ
         
        - n_estimators : íŠ¸ë¦¬ì˜ ê°œìˆ˜
       
          - ë†’ì„ìˆ˜ë¡ ì•ˆì •ì ìœ¼ë¡œ ì˜ˆì¸¡ ê°€ëŠ¥, í•™ìŠµ ì‹œê°„ ì¦ê°€
         
          - ê¸°ë³¸ê°’ : 100
         
      - ëœë¤í¬ë ˆìŠ¤íŠ¸ ë¶„ë¥˜ì—ì„œ max_depth ëŠ” 3\~7, n_estimators ëŠ” 200\~500 ì •ë„ë¡œ ì ìš©

<br>

|ë°ì´í„° ì „ì²˜ë¦¬/í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹|ROC-AUC|ì œì¶œ|
|-|-|-|
|ë² ì´ìŠ¤ë¼ì¸|0.8002739726027398|ì„ íƒ / 1ì°¨ ì œì¶œ|
|ìŠ¤ì¼€ì¼ë§(Standard Scaler)|0.8005479452054794||
|ìŠ¤ì¼€ì¼ë§(Min-Max Scaler)|0.8031506849315069|ì„ íƒ|
|ìŠ¤ì¼€ì¼ë§(Robust Scaler)|0.7987671232876713||
|max_depth = 3|0.8123287671232877||
|max_depth = 5|0.8156164383561644|ì„ íƒ|
|max_depth = 7|0.8054794520547945||
|max_depth = 5, n_estimators = 200|0.8216438356164385||
|max_depth = 5, n_estimators = 400|0.821917808219178||
|max_depth = 5, n_estimators = 600|0.8241095890410959|ì„ íƒ / ìµœì¢… ì œì¶œ|

<br>

> ì½”ë“œ
```python
  # 2. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
  import pandas as pd
  
  train = pd.read_csv('./data/diabetes_train.csv')
  test = pd.read_csv('./data/diabetes_test.csv')
  
  # 4. ë°ì´í„° ì „ì²˜ë¦¬
  # ìŠ¤ì¼€ì¼ë§
  target = train.pop('Outcome')
  from sklearn.preprocessing import StandardScaler
  from sklearn.preprocessing import MinMaxScaler
  from sklearn.preprocessing import RobustScaler
  scaler = RobustScaler()
  train = scaler.fit_transform(train)
  test = scaler.transform(test)
  
  # 5. ê²€ì¦ ë°ì´í„° ë‚˜ëˆ„ê¸°
  from sklearn.model_selection import train_test_split
  X_train, X_val, y_train, y_val = train_test_split(train, target, test_size=0.2, random_state=0)
  
  # 6. ë¨¸ì‹ ëŸ¬ë‹ í•™ìŠµ ë° í‰ê°€
  from sklearn.ensemble import RandomForestClassifier
  rf = RandomForestClassifier(max_depth=5, n_estimators=600, random_state=0)
  rf.fit(X_train, y_train)
  pred = rf.predict_proba(X_val)
  
  from sklearn.metrics import roc_auc_score
  roc_auc = roc_auc_score(y_val, pred[:, 1])
  print('roc_auc :', roc_auc)

  # 7. ì˜ˆì¸¡ ë° ê²°ê³¼ íŒŒì¼ ìƒì„±
  pred = rf.predict_proba(test)
  submit = pd.DataFrame({'pred':pred[:, 1]})
  submit.to_csv('result1.csv', index=False)
```

> ê²°ê³¼
```python
  roc_auc : 0.8241095890410959
```

<br>

---

<br>

SECTION02 ì´ì§ ì—¬ë¶€ ì˜ˆì¸¡
---
- ìƒˆë¡œìš´ ì¼ìë¦¬ë¥¼ ì°¾ì„ì§€ ì˜ˆì¸¡

  - ì œê³µëœ ë°ì´í„° ëª©ë¡ : hr_train.csv, hr_test.csv
 
  - ì˜ˆì¸¡í•  ì»¬ëŸ¼ : target(0: ìƒˆ ì¼ìë¦¬ë¥¼ ì°¾ì§€ ì•ŠìŒ, 1: ìƒˆ ì¼ìë¦¬ë¥¼ ì°¾ìŒ)
 
- í•™ìŠµìš© ë°ì´í„°(train) ì´ìš©í•´ ìƒˆ ì¼ìë¦¬ë¥¼ ì°¾ì„ì§€ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ ìƒì„±

- í‰ê°€ìš© ë°ì´í„°(test)ì— ì ìš©í•´ ì–»ì€ ì˜ˆì¸¡ê°’ì„ ì•„ë˜ í˜•ì‹ì˜ csv íŒŒì¼ë¡œ ìƒì„±

  - ì œì¶œ íŒŒì¼ì€ ë‹¤ìŒ 2ê°œì˜ ì»¬ëŸ¼ í¬í•¨
 
    - pred : ì˜ˆì¸¡ê°’(ì´ì§í•  í™•ë¥ )
   
    - ì œì¶œ íŒŒì¼ëª… : 'result2.csv'
   
  - ì œì¶œí•œ ëª¨ë¸ì˜ ì„±ëŠ¥ì€ ROC-AUC í‰ê°€ì§€í‘œì— ë”°ë¼ ì±„ì 

<br>

### 01. ë² ì´ìŠ¤ë¼ì¸
- ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ê³ , ê°„ë‹¨í•œ íƒìƒ‰ì  ë°ì´í„° ë¶„ì„ ì§„í–‰

<br>

#### (1) EDA

> ì½”ë“œ
```python
  # 1. ë¬¸ì œ ì •ì˜
  # í‰ê°€ : roc-auc
  # target : target
  # ìµœì¢… íŒŒì¼ : result.csv(ì»¬ëŸ¼ 1ê°œ pred, 1 í™•ë¥ ê°’)
  
  # 2. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
  import pandas as pd
  
  train = pd.read_csv('./data/hr_train.csv')
  test = pd.read_csv('./data/hr_test.csv')
  
  # 3. íƒìƒ‰ì  ë°ì´í„° ë¶„ì„(EDA)
  print('==== ë°ì´í„° ì •ë³´(ìë£Œí˜•) ====')
  print(train.info())
  
  print('\n ==== train ê²°ì¸¡ì¹˜ ìˆ˜ ====')
  print(train.isnull().sum())
  
  print('\n ==== test ê²°ì¸¡ì¹˜ ìˆ˜ ====')
  print(test.isnull().sum())
  
  print('\n ==== train ì¹´í…Œê³ ë¦¬ë³„ ìˆ˜ ====')
  print(train.nunique())
  
  print('\n ==== test ì¹´í…Œê³ ë¦¬ë³„ ìˆ˜ ====')
  print(test.nunique())
  
  print('\n ==== target ë¹ˆë„ ====')
  print(train['target'].value_counts())
```

> ê²°ê³¼
```python
  ==== ë°ì´í„° ì •ë³´(ìë£Œí˜•) ====
  <class 'pandas.core.frame.DataFrame'>
  RangeIndex: 15326 entries, 0 to 15325
  Data columns (total 14 columns):
   #   Column                  Non-Null Count  Dtype  
  ---  ------                  --------------  -----  
   0   enrollee_id             15326 non-null  int64  
   1   city                    15326 non-null  object 
   2   city_development_index  15326 non-null  float64
   3   gender                  11750 non-null  object 
   4   relevent_experience     15326 non-null  object 
   5   enrolled_university     15012 non-null  object 
   6   education_level         14961 non-null  object 
   7   major_discipline        13045 non-null  object 
   8   experience              15272 non-null  object 
   9   company_size            10539 non-null  object 
   10  company_type            10383 non-null  object 
   11  last_new_job            14984 non-null  object 
   12  training_hours          15326 non-null  int64  
   13  target                  15326 non-null  float64
  dtypes: float64(2), int64(2), object(10)

  memory usage: 1.6+ MB
  None
  
   ==== train ê²°ì¸¡ì¹˜ ìˆ˜ ====
  enrollee_id                  0
  city                         0
  city_development_index       0
  gender                    3576
  relevent_experience          0
  enrolled_university        314
  education_level            365
  major_discipline          2281
  experience                  54
  company_size              4787
  company_type              4943
  last_new_job               342
  training_hours               0
  target                       0
  dtype: int64
  
   ==== test ê²°ì¸¡ì¹˜ ìˆ˜ ====
  enrollee_id                  0
  city                         0
  city_development_index       0
  gender                     932
  relevent_experience          0
  enrolled_university         72
  education_level             95
  major_discipline           532
  experience                  11
  company_size              1151
  company_type              1197
  last_new_job                81
  training_hours               0
  dtype: int64
  
   ==== train ì¹´í…Œê³ ë¦¬ë³„ ìˆ˜ ====
  enrollee_id               15326
  city                        123
  city_development_index       93
  gender                        3
  relevent_experience           2
  enrolled_university           3
  education_level               5
  major_discipline              6
  experience                   22
  company_size                  8
  company_type                  6
  last_new_job                  6
  training_hours              241
  target                        2
  dtype: int64
  
   ==== test ì¹´í…Œê³ ë¦¬ë³„ ìˆ˜ ====
  enrollee_id               3832
  city                       113
  city_development_index      87
  gender                       3
  relevent_experience          2
  enrolled_university          3
  education_level              5
  major_discipline             6
  experience                  22
  company_size                 8
  company_type                 6
  last_new_job                 6
  training_hours             235
  dtype: int64
  
   ==== target ë¹ˆë„ ====
  target
  0.0    11517
  1.0     3809
  Name: count, dtype: int64
```
- ìˆ˜ì¹˜í˜• ì»¬ëŸ¼(ë³€ìˆ˜) : 4ê°œ, ë²”ì£¼í˜• ì»¬ëŸ¼(ë³€ìˆ˜) : 10ê°œ

- ê²°ì¸¡ì¹˜ë„ train ê³¼ test ëª¨ë‘ 8ê°œì˜ ì»¬ëŸ¼ì— æœ‰

  - ëª¨ë‘ object ìë£Œí˜•

- nunique() í™œìš©í•´ ì»¬ëŸ¼ë³„ ì¹´í…Œê³ ë¦¬ ìˆ˜ í™•ì¸

  - object ì™¸ì˜ ìë£Œí˜•ë„ í¬í•¨ë¨
 
  - object í˜•ë§Œ í™•ì¸í•˜ê³  ì‹¶ìœ¼ë©´?
 
    - train.select_dtypes(include=['object']).unique()
   
  - city ì»¬ëŸ¼ì€ train ê³¼ test ê°€ ë‹¤ë¦„

<br>

#### ğŸ’¡ train ê³¼ test ë²”ì£¼í˜• ë°ì´í„° ë¹„êµ
- object ê°€ ì»¬ëŸ¼ê³¼ ì¹´í…Œê³ ë¦¬ê°€ ë§ì´ ìˆì„ ë•ŒëŠ” train ê³¼ test ì˜ ì¹´í…Œê³ ë¦¬ ì°¨ì´ë¥¼ ëˆˆìœ¼ë¡œ ë¹„êµí•˜ê¸° ì–´ë ¤ì›€

- ì¹´í…Œê³ ë¦¬ ê°œìˆ˜ê°€ ê°™ë”ë¼ë„ ê°’ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ

- ì¤‘ë³µëœ ê°’ì„ í—ˆìš©í•˜ì§€ ì•ŠëŠ” set() í™œìš©í•´ 2ê°œì˜ ë°ì´í„° ì§‘í•© ê°„ì— ì •í™•í•œ ë¹„êµ ê°€ëŠ¥

> ì½”ë“œ
```python
  import pandas as pd
  
  train = pd.read_csv('./data/hr_train.csv')
  test = pd.read_csv('./data/hr_test.csv')
  
  cols = train.select_dtypes(include='object').columns
  
  for col in cols:
      set_train = set(train[col])
      set_test = set(test[col])
      same = (set_train == set_test)
      if same:
          print(col, '\t ì¹´í…Œê³ ë¦¬ ë™ì¼í•¨')
      else:
          print(col, '\t ì¹´í…Œê³ ë¦¬ ë™ì¼í•˜ì§€ ì•ŠìŒ')
```

> ê²°ê³¼
```python
  city 	 ì¹´í…Œê³ ë¦¬ ë™ì¼í•˜ì§€ ì•ŠìŒ
  gender 	 ì¹´í…Œê³ ë¦¬ ë™ì¼í•¨
  relevent_experience 	 ì¹´í…Œê³ ë¦¬ ë™ì¼í•¨
  enrolled_university 	 ì¹´í…Œê³ ë¦¬ ë™ì¼í•¨
  education_level 	 ì¹´í…Œê³ ë¦¬ ë™ì¼í•¨
  major_discipline 	 ì¹´í…Œê³ ë¦¬ ë™ì¼í•¨
  experience 	 ì¹´í…Œê³ ë¦¬ ë™ì¼í•¨
  company_size 	 ì¹´í…Œê³ ë¦¬ ë™ì¼í•¨
  company_type 	 ì¹´í…Œê³ ë¦¬ ë™ì¼í•¨
  last_new_job 	 ì¹´í…Œê³ ë¦¬ ë™ì¼í•¨
```

<br>

#### (2) ì „ì²˜ë¦¬ ë° ì˜ˆì¸¡

> ì½”ë“œ
```python
  # 4. ë°ì´í„° ì „ì²˜ë¦¬
  target = train.pop('target')
  
  # ê²°ì¸¡ì¹˜ ì²˜ë¦¬
  train = train.fillna('X')
  test = test.fillna('X')
  
  # train ê³¼ test í•©ì³ì„œ ì›-í•« ì¸ì½”ë”©
  combined = pd.concat([train, test])
  combined_dummies = pd.get_dummies(combined)
  n_train = len(train)
  train = combined_dummies[:n_train]
  test = combined_dummies[n_train:]
  
  # 5. ê²€ì¦ ë°ì´í„° ë‚˜ëˆ„ê¸°
  from sklearn.model_selection import train_test_split
  X_train, X_val, y_train, y_val = train_test_split(train, target, test_size=0.2, random_state=0)
  
  # 6. ë¨¸ì‹ ëŸ¬ë‹ í•™ìŠµ ë° í‰ê°€
  from sklearn.ensemble import RandomForestClassifier
  rf = RandomForestClassifier(random_state=0)
  rf.fit(X_train, y_train)
  pred = rf.predict_proba(X_val)
  
  from sklearn.metrics import roc_auc_score
  roc_auc = roc_auc_score(y_val, pred[:, 1])
  print('roc_auc :', roc_auc)
  
  # 7. ì˜ˆì¸¡ ë° ê²°ê³¼ íŒŒì¼ ìƒì„±
  pred = rf.predict_proba(test)
  submit = pd.DataFrame({'pred': pred[:, 1]})
  submit.to_csv('result2.csv', index=False)
```
- ë¹ˆ ê°’ì€ ë³„ë„ë¡œ X ë¡œ í‘œê¸°

- ì»¬ëŸ¼ì˜ ìˆ˜ê°€ ë‹¤ë¥´ë¯€ë¡œ train ê³¼ test ë¥¼ í•©ì³ ì›-í•« ì¸ì½”ë”© ì§„í–‰ í›„ ë‹¤ì‹œ train ê³¼ test ë¡œ ë‚˜ëˆ”

- ëœë¤í¬ë ˆìŠ¤íŠ¸ë¡œ ëª¨ë¸ì„ ë§Œë“¤ê³  ì˜ˆì¸¡

> ê²°ê³¼
```python
  roc_auc : 0.7730742036233207
```

<br>

### 02. ì„±ëŠ¥ ê°œì„ 
- **ë°ì´í„° ì „ì²˜ë¦¬**

  - **ë ˆì´ë¸” ì¸ì½”ë”©** : ë² ì´ìŠ¤ë¼ì¸ì— ìˆëŠ” ì›-í•« ì¸ì½”ë”©ì„ ë ˆì´ë¸” ì¸ì½”ë”©ìœ¼ë¡œ ë³€ê²½
 
  - ìŠ¤ì¼€ì¼ë§(Standard Scaler, Min-Max Scaler, Robust Scaler)
 
  - id ì œê±°
 
- **í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹**

  - **max-depth** : 3 ~ 7
 
  - **n_estimators** : 200 ~ 500

- ìœ„ì—ì„œëŠ” ê²°ì¸¡ì¹˜ê°€ object ìë£Œí˜•ì´ë¼ ì¼ê´„ X ë¡œ ì²˜ë¦¬

  - ê° ì»¬ëŸ¼ë³„ë¡œ ë‹¤ë¥¸ ê²°ì¸¡ ì²˜ë¦¬ í•  ìˆ˜ë„ ìˆìŒ

<br>

|ë°ì´í„° ì „ì²˜ë¦¬/í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹|ROC-AUC|ì œì¶œ|
|ë² ì´ìŠ¤ë¼ì¸|0.7730742036233207|ì„ íƒ / 1ì°¨ ì œì¶œ|
|ë ˆì´ë¸” ì¸ì½”ë”©|0.7747496616891663|ì„ íƒ|
|id ì œê±°|0.7649556215788462|ì„±ëŠ¥ ë–¨ì–´ì§ - ìƒëµ|
|ìŠ¤ì¼€ì¼ë§(Standard Scaler)|0.7749234996090111||
|ìŠ¤ì¼€ì¼ë§(Min-Max Scaler)|0.7749741291715249||
|ìŠ¤ì¼€ì¼ë§(Robust Scaler)|0.7750549023464022|ì„ íƒ|
|max-depth = 3|0.775941358675039||
|max-depth = 5|0.7796899948960718||
|max-depth = 7|0.7816010413886431|ì„ íƒ|
|max-depth = 7, n_estimators = 200|0.7825363713412095|ì„ íƒ / 2ì°¨ ì œì¶œ|
|max-depth = 7, n_estimators = 400|0.7825246650839807||
|max-depth = 7, n_estimators = 600|0.7823490712255514||

<br>

> ì½”ë“œ
```python
  # 2. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
  import pandas as pd
  train = pd.read_csv('./data/hr_train.csv')
  test = pd.read_csv('./data/hr_test.csv')
  
  # 4. ë°ì´í„° ì „ì²˜ë¦¬
  target = train.pop('target')
  
  # ê²°ì¸¡ì¹˜ ì œê±°
  train = train.fillna('X')
  test = test.fillna('X')
  
  # ë ˆì´ë¸” ì¸ì½”ë”©
  from sklearn.preprocessing import LabelEncoder
  combined = pd.concat([train, test])
  cols = train.select_dtypes(include = 'object').columns
  for col in cols:
      le = LabelEncoder()
      combined[col] = le.fit_transform(combined[col])
  n_train = len(train)
  train = combined[:n_train]
  test = combined[n_train:]
  
  # id ì œê±°   (ì„±ëŠ¥ ë–¨ì–´ì§)
  # train = train.drop('enrollee_id', axis=1)
  # test = test.drop('enrollee_id', axis=1)
  
  # ìŠ¤ì¼€ì¼ë§
  from sklearn.preprocessing import RobustScaler
  scaler = RobustScaler()
  n_cols = train.select_dtypes(exclude='object').columns
  train = scaler.fit_transform(train)
  test = scaler.transform(test)
  
  # 5. ê²€ì¦ ë°ì´í„° ë¶„í• 
  from sklearn.model_selection import train_test_split
  X_train, X_val, y_train, y_val = train_test_split(train, target, test_size=0.2, random_state=0)
  
  # 6. ë¨¸ì‹ ëŸ¬ë‹ í•™ìŠµ ë° í‰ê°€
  from sklearn.ensemble import RandomForestClassifier
  rf = RandomForestClassifier(max_depth=7, n_estimators=200, random_state=0)
  rf.fit(X_train, y_train)
  pred = rf.predict_proba(X_val)
  
  from sklearn.metrics import roc_auc_score
  roc_auc = roc_auc_score(y_val, pred[:, 1])
  print('roc_auc :', roc_auc)

  # 7. ì˜ˆì¸¡ ë° ê²°ê³¼ íŒŒì¼ ìƒì„±
  pred = rf.predict_proba(test)
  submit = pd.DataFrame({'pred': pred[:, 1]})
  submit.to_csv('result2.csv', index=False)

  # ê²°ê³¼ ìƒ˜í”Œ
  print('\n==== result2.csv ìƒ˜í”Œ ë°ì´í„° 5ê°œ ====')
  print(pd.read_csv('result2.csv').head())
```

> ê²°ê³¼
```python
  roc_auc : 0.7825363713412095
  
  ==== result2.csv ìƒ˜í”Œ ë°ì´í„° 5ê°œ ====
         pred
  0  0.188463
  1  0.529855
  2  0.600765
  3  0.080796
  4  0.109437
```

<br>

---

<br>

SECTION03 ì‹ ìš©ì¹´ë“œ ì‹ ì²œìì˜ ë¯¸ë˜ ì‹ ìš© ì˜ˆì¸¡
---
- ì‹ ìš©ì¹´ë“œ ì‹ ì²­ìì˜ ì±„ë¬´ ë¶ˆì´í–‰ ì˜ˆì¸¡

  - ì œê³µëœ ë°ì´í„° ëª©ë¡ : creditcard_train.csv, creditcard_test.csv
 
  - ì˜ˆì¸¡í•  ì»¬ëŸ¼ : target(0: ì±„ë¬´ ì´í–‰, 1: ì±„ë¬´ ë¶ˆì´í–‰)
 
- í•™ìŠµìš© ë°ì´í„°(train)ì„ ì´ìš©í•´ ì‹ ìš©ì¹´ë“œ ì‹ ì²­ìì˜ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¯¸ë˜ì˜ ì±„ë¬´ ë¶ˆì´í–‰ ì˜ˆì¸¡ ëª¨ë¸ ìƒì„±

- í‰ê°€ìš© ë°ì´í„°(test)ì— ì ìš©í•´ ì–»ì€ ì˜ˆì¸¡ê°’ì„ ì•„ë˜ ì™€ ê°™ì€ í˜•ì‹ì˜ csv íŒŒì¼ë¡œ ìƒì„±

  - ì œì¶œ íŒŒì¼ì€ ë‹¤ìŒ 1ê°œì˜ ì»¬ëŸ¼ í¬í•¨
 
    - pred : ì˜ˆì¸¡ê°’
   
    - ì œì¶œ íŒŒì¼ëª… : 'result3.csv'
   
  - ì œì¶œí•œ ëª¨ë¸ì˜ ì„±ëŠ¥ì€ f1 í‰ê°€ì§€í‘œì— ë”°ë¼ ì±„ì 

<br>

### 01. ë² ì´ìŠ¤ë¼ì¸
- ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ê³ , ê°„ë‹¨í•œ íƒìƒ‰ì  ë°ì´í„° ë¶„ì„ ì§„í–‰

#### (1) EDA

> ì½”ë“œ
```python
  # 1. ë¬¸ì œ ì •ì˜
  # í‰ê°€ : f1
  # target : STATUS
  # ìµœì¢… íŒŒì¼ : result.csv(ì»¬ëŸ¼ 1ê°œ pred)
  
  # 2. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
  import pandas as pd
  
  train = pd.read_csv('./data/creditcard_train.csv')
  test = pd.read_csv('./data/creditcard_test.csv')
  
  # 3. íƒìƒ‰ì  ë°ì´í„° ë¶„ì„(EDA)
  print('==== ë°ì´í„° í¬ê¸° ====')
  print(train.shape, test.shape)
  
  print('\n==== ë°ì´í„° ì •ë³´(ìë£Œí˜•) ====')
  print(train.info())
  
  print('\n==== train ê²°ì¸¡ì¹˜ ìˆ˜ ====')
  print(train.isnull().sum())
  
  print('\n==== test ê²°ì¸¡ì¹˜ ìˆ˜ ====')
  print(test.isnull().sum())
  
  print('\n==== ë²”ì£¼í˜• ë°ì´í„° ì¹´í…Œê³ ë¦¬ =====')
  cols = train.select_dtypes(include='object').columns
  for col in cols:
      set_train = set(train[col])
      set_test = set(test[col])
      same = (set_train == set_test)
      if same:
          print(col, '\tì¹´í…Œê³ ë¦¬ ë™ì¼í•¨')
      else:
          print(col, '\tì¹´í…Œê³ ë¦¬ ë™ì¼í•˜ì§€ ì•ŠìŒ')
          
  print('\n==== target ë¹ˆë„ ====')
  print(train['STATUS'].value_counts())
```

> ê²°ê³¼
```python
  ==== ë°ì´í„° í¬ê¸° ====
  (25519, 19) (7591, 18)
  
  ==== ë°ì´í„° ì •ë³´(ìë£Œí˜•) ====
  <class 'pandas.core.frame.DataFrame'>
  RangeIndex: 25519 entries, 0 to 25518
  Data columns (total 19 columns):
   #   Column               Non-Null Count  Dtype  
  ---  ------               --------------  -----  
   0   ID                   25519 non-null  int64  
   1   CODE_GENDER          25519 non-null  object 
   2   FLAG_OWN_CAR         25519 non-null  object 
   3   FLAG_OWN_REALTY      25519 non-null  object 
   4   CNT_CHILDREN         25519 non-null  int64  
   5   AMT_INCOME_TOTAL     25519 non-null  float64
   6   NAME_INCOME_TYPE     25519 non-null  object 
   7   NAME_EDUCATION_TYPE  25519 non-null  object 
   8   NAME_FAMILY_STATUS   25519 non-null  object 
   9   NAME_HOUSING_TYPE    25519 non-null  object 
   10  DAYS_BIRTH           25519 non-null  int64  
   11  DAYS_EMPLOYED        25519 non-null  int64  
   12  FLAG_MOBIL           25519 non-null  int64  
   13  FLAG_WORK_PHONE      25519 non-null  int64  
   14  FLAG_PHONE           25519 non-null  int64  
   15  FLAG_EMAIL           25519 non-null  int64  
   16  OCCUPATION_TYPE      17543 non-null  object 
   17  CNT_FAM_MEMBERS      25519 non-null  float64
   18  STATUS               25519 non-null  int64  
  dtypes: float64(2), int64(9), object(8)
  memory usage: 3.7+ MB
  None
  
  ==== train ê²°ì¸¡ì¹˜ ìˆ˜ ====
  ID                        0
  CODE_GENDER               0
  FLAG_OWN_CAR              0
  FLAG_OWN_REALTY           0
  CNT_CHILDREN              0
  AMT_INCOME_TOTAL          0
  NAME_INCOME_TYPE          0
  NAME_EDUCATION_TYPE       0
  NAME_FAMILY_STATUS        0
  NAME_HOUSING_TYPE         0
  DAYS_BIRTH                0
  DAYS_EMPLOYED             0
  FLAG_MOBIL                0
  FLAG_WORK_PHONE           0
  FLAG_PHONE                0
  FLAG_EMAIL                0
  OCCUPATION_TYPE        7976
  CNT_FAM_MEMBERS           0
  STATUS                    0
  dtype: int64
  
  ==== test ê²°ì¸¡ì¹˜ ìˆ˜ ====
  ID                     0
  CODE_GENDER            0
  FLAG_OWN_CAR           0
  FLAG_OWN_REALTY        0
  CNT_CHILDREN           0
  AMT_INCOME_TOTAL       0
  NAME_INCOME_TYPE       0
  NAME_EDUCATION_TYPE    0
  NAME_FAMILY_STATUS     0
  NAME_HOUSING_TYPE      0
  DAYS_BIRTH             0
  DAYS_EMPLOYED          0
  FLAG_MOBIL             0
  FLAG_WORK_PHONE        0
  FLAG_PHONE             0
  FLAG_EMAIL             0
  OCCUPATION_TYPE        0
  CNT_FAM_MEMBERS        0
  dtype: int64
  
  ==== ë²”ì£¼í˜• ë°ì´í„° ì¹´í…Œê³ ë¦¬ =====
  CODE_GENDER 	ì¹´í…Œê³ ë¦¬ ë™ì¼í•¨
  FLAG_OWN_CAR 	ì¹´í…Œê³ ë¦¬ ë™ì¼í•¨
  FLAG_OWN_REALTY 	ì¹´í…Œê³ ë¦¬ ë™ì¼í•¨
  NAME_INCOME_TYPE 	ì¹´í…Œê³ ë¦¬ ë™ì¼í•¨
  NAME_EDUCATION_TYPE 	ì¹´í…Œê³ ë¦¬ ë™ì¼í•¨
  NAME_FAMILY_STATUS 	ì¹´í…Œê³ ë¦¬ ë™ì¼í•¨
  NAME_HOUSING_TYPE 	ì¹´í…Œê³ ë¦¬ ë™ì¼í•¨
  OCCUPATION_TYPE 	ì¹´í…Œê³ ë¦¬ ë™ì¼í•˜ì§€ ì•ŠìŒ
  
  ==== target ë¹ˆë„ ====
  STATUS
  0    25085
  1      434
  Name: count, dtype: int64
```
- train ë°ì´í„°ì˜ OCCUPATION_TYPE ì»¬ëŸ¼ì— ê²°ì¸¡ì¹˜ æœ‰

- ë¶ˆê· í˜• ì‹¬í•¨

  - ì •ìƒ(ì±„ë¬´ ì´í–‰)ì€ 25,085ê°œê°€ ìˆì§€ë§Œ, ë¹„ì •ìƒ(ì±„ë¬´ ë¶ˆì´í–‰)ì€ 434ê°œë°–ì— ì—†ìŒ
 
  - ë¨¸ì‹ ëŸ¬ë‹ì—ì„œ í”íˆ ë°œìƒí•˜ëŠ” ë¬¸ì œ

- ë¶„ë¥˜ ë¬¸ì œì—ì„œ í•œ í´ë˜ìŠ¤ê°€ ë‹¤ë¥¸ í´ë˜ìŠ¤ì˜ ìˆ˜ë³´ë‹¤ ì›”ë“±íˆ ë§ì€ ê²½ìš°

  - ëª¨ë¸ì€ ë‹¤ìˆ˜ì˜ í´ë˜ìŠ¤ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë° í¸í–¥ë  ìˆ˜ ìˆìŒ

<br>

#### (2) ì „ì²˜ë¦¬ ë° ì˜ˆì¸¡
- ë°ì´í„°(í–‰ ë˜ëŠ” ì»¬ëŸ¼) ì‚­ì œì‹œ ë°˜ë“œì‹œ ì‚­ì œ ì „ê³¼ í›„ í¬ê¸° ë¹„êµ

  - ì˜ˆìƒí•œ ìˆ«ìë§Œí¼ ì‚­ì œê°€ ì§„í–‰ë˜ì—ˆëŠ”ì§€ ê²€ì¦í•  í•„ìš” ìˆìŒ
 
  - í–‰ì„ ì‚­ì œí•œë‹¤ë©´ íƒ€ê²Ÿ ì»¬ëŸ¼ì€ í–‰ì„ ì‚­ì œí•œ ì´í›„ì— ë³€ìˆ˜ë¡œ ì˜®ê²¨ì•¼ í•¨

> ì½”ë“œ
```python
  # 4. ë°ì´í„° ì „ì²˜ë¦¬
  # ê²°ì¸¡ì¹˜ ì²˜ë¦¬
  print('ì‚­ì œ ì „ :', train.shape)
  train.dropna(subset=['OCCUPATION_TYPE'], inplace=True)
  print('ì‚­ì œí›„: ', train.shape)
  
  target = train.pop('STATUS')
  
  # ì›-í•« ì¸ì½”ë”©
  train = pd.get_dummies(train)
  test = pd.get_dummies(test)
  
  # 5. ê²€ì¦ ë°ì´í„° ë¶„í• 
  from sklearn.model_selection import train_test_split
  X_train, X_val, y_train, y_val = train_test_split(train, target, test_size=0.2, random_state=0)
  
  # 6. ë¨¸ì‹ ëŸ¬ë‹ í•™ìŠµ ë° í‰ê°€
  from sklearn.ensemble import RandomForestClassifier
  rf = RandomForestClassifier(random_state=0)
  rf.fit(X_train, y_train)
  pred = rf.predict(X_val)
  
  from sklearn.metrics import f1_score
  f1 = f1_score(y_val, pred)
  print('\nF1 :', f1)
  
  # 7. ì˜ˆì¸¡ ë° ê²°ê³¼ íŒŒì¼ ìƒì„±
  pred = rf.predict(test)
  submit = pd.DataFrame({'pred': pred})
  submit.to_csv('result3.csv', index = False)
  
  print('\n==== ì œì¶œ íŒŒì¼ ìƒ˜í”Œ ë°ì´í„° ====')
  print(pd.read_csv('result3.csv').head())
```
- ë² ì´ìŠ¤ë¼ì¸ì—ì„œ ë²”ì£¼í˜• ìë£Œí˜•ì€ ì›-í•« ì¸ì½”ë”© ì ìš©

- í‰ê°€ì§€í‘œê°€ F1 ìŠ¤ì½”ì–´ì´ë¯€ë¡œ ì˜ˆì¸¡ì€ predict() ì‚¬ìš©

  - 0 ë„ëŠ” 1 ì˜ ê²°ê³¼ê°’ ì–»ìŒ

> ê²°ê³¼
```python
  ì‚­ì œ ì „ : (25519, 19)
  ì‚­ì œí›„:  (17543, 19)
  
  F1 : 0.22018348623853212
  
  ==== ì œì¶œ íŒŒì¼ ìƒ˜í”Œ ë°ì´í„° ====
     pred
  0     0
  1     0
  2     0
  3     0
  4     0
```

<br>

### 02. ì„±ëŠ¥ ê°œì„ 
- ì‹¬ê°í•œ ë¶ˆê· í˜• ë°ì´í„°ì¼ ê²½ìš° í‰ê°€ì§€í‘œê°€ ë‚®ê²Œ ë‚˜ì˜¬ ìˆ˜ë„ ìˆìŒ

- F1 ìŠ¤ì½”ì–´ëŠ” 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ì€ ì„±ëŠ¥

- **ë°ì´í„° ì „ì²˜ë¦¬**

  - **ë ˆì´ë¸” ì¸ì½”ë”©** : ë² ì´ìŠ¤ë¼ì¸ì— ìˆëŠ” ì›-í•« ì¸ì½”ë”©ì„ ë ˆì´ë¸” ì¸ì½”ë”©ìœ¼ë¡œ ë³€ê²½
 
  - ìŠ¤ì¼€ì¼ë§(Standard Scaler, Min-Max Scaler, Robust Scaler) : íš¨ê³¼ X
 
  - id ì œê±°
 
- **í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹**

  - **max_depth** : 3 ~ 7
 
  - **n_estimaors** : 200 ~ 500
 
  - **class_weight**='balanced'

<br>

|ë°ì´í„° ì „ì²˜ë¦¬/í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹|F1|ì œì¶œ|
|-|-|-|
|ë² ì´ìŠ¤ë¼ì¸|0.22018348623853212|ì„ íƒ / 1ì°¨ ì œì¶œ|
|ë ˆì´ë¸” ì¸ì½”ë”©|0.23636363636363636|ì„ íƒ|
|ê²°ì¸¡ì¹˜(ìµœë¹ˆê°’)|0.2727272727272727|ì„ íƒ|
|id ì œì™¸|0.2972972972972973|ì„ íƒ|
|ìŠ¤ì¼€ì¼ë§(Standard, Min-Max, Robust)|0.2972972972972973||
|max_depth = 3, 5, 7|0.0||
|n_estimators = 200|0.29931972789115646|ì„ íƒ / 2ì°¨ ì œì¶œ|
|n_estimators = 400|0.2972972972972973||
|n_estimators = 500|0.2972972972972973||
|n_estimators = 200, class_weight = 'balanced'|0.3241106719367589|ì„ íƒ / 3ì°¨ ì œì¶œ|

<br>

> ì½”ë“œ
```python
  # 2. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
  import pandas as pd
  
  train = pd.read_csv('./data/creditcard_train.csv')
  test = pd.read_csv('./data/creditcard_test.csv')
  
  # 4. ë°ì´í„° ì „ì²˜ë¦¬
  # ê²°ì¸¡ì¹˜ ì²˜ë¦¬(ìµœë¹ˆê°’)
  freq = train['OCCUPATION_TYPE'].mode()[0]
  train['OCCUPATION_TYPE'] = train['OCCUPATION_TYPE'].fillna(freq)
  test['OCCUPATION_TYPE'] = test['OCCUPATION_TYPE'].fillna(freq)
  
  target = train.pop('STATUS')
  
  # id ì œì™¸
  train = train.drop('ID', axis=1)
  test = test.drop('ID', axis=1)
  
  # ìŠ¤ì¼€ì¼ë§(ì„±ëŠ¥ ê°œì„  íš¨ê³¼ ì—†ìŒ)
  # from sklearn.preprocessing import RobustScaler
  # scaler = RobustScaler()
  # n_cols = train.select_dtypes(exclude='object').columns[:-1]     # STATUS ì œì™¸í•œ int, float
  # train[n_cols] = scaler.fit_transform(train[n_cols])
  # test[n_cols] = scaler.transform(test[n_cols])
  
  # ë ˆì´ë¸” ì¸ì½”ë”©
  from sklearn.preprocessing import LabelEncoder
  cols = train.select_dtypes(include='object').columns
  for col in cols:
      le = LabelEncoder()
      train[col] = le.fit_transform(train[col])
      test[col] = le.transform(test[col])
      
  # 5. ê²€ì¦ ë°ì´í„° ë‚˜ëˆ„ê¸°
  from sklearn.model_selection import train_test_split
  X_train, X_val, y_train, y_val = train_test_split(train, target, test_size=0.2, random_state=0)
  
  # 6. ë¨¸ì‹ ëŸ¬ë‹ í•™ìŠµ ë° í‰ê°€
  from sklearn.ensemble import RandomForestClassifier
  rf = RandomForestClassifier(n_estimators=500, class_weight='balanced', random_state=0)
  rf.fit(X_train, y_train)
  pred = rf.predict(X_val)
  
  from sklearn.metrics import f1_score
  f1 = f1_score(y_val, pred)
  print('F1 :', f1)
  
  # 7. ì˜ˆì¸¡ ë° ê²°ê³¼ íŒŒì¼ ìƒì„±
  pred = rf.predict(test)
  submit = pd.DataFrame({'pred': pred})
  submit.to_csv('result3.csv', index=False)
```
- í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¡œëŠ” í° íš¨ê³¼ ë³´ê¸° ì–´ë ¤ì›€

  - íŠ¸ë¦¬ì˜ ê¹Šì´ë¥¼ ì œí•œí•˜ëŠ” max_depth ëŠ” ê²°ê³¼ê°€ 0ì ìœ¼ë¡œ ë§¤ìš° ì„±ëŠ¥ì´ ì €í•˜ë¨
  
  - n_estimators ëŠ” ì•½ê°„ì˜ ì°¨ì´ë§Œ ìˆìŒ

- ëœë¤í¬ë ˆìŠ¤íŠ¸ì—ëŠ” ë¶ˆê· í˜•í•œ í´ë˜ìŠ¤ë¥¼ ìë™ìœ¼ë¡œ ê· í˜• ìˆê²Œ ì¡°ì •í•  ìˆ˜ ìˆëŠ” calss_weight í™œìš© ë°©ë²• æœ‰

  - ê¸°ë³¸ê°’ì€ ëª¨ë“  í´ë˜ìŠ¤ì— ë™ì¼í•œ ê°€ì¤‘ì¹˜ë¥¼ ë‘ 
 
  - ë¶ˆê· í˜• ë°ì´í„°ì¼ ê²½ìš° calss_weight='balanced' ì„¤ì •
 
    - ì ì€ ìˆ˜ì˜ ìƒ˜í”Œì„ ê°€ì§„ í´ë˜ìŠ¤ì— ë” í° ê°€ì¤‘ì¹˜ë¥¼ ìë™ìœ¼ë¡œ ë¶€ì—¬

> ê²°ê³¼
```python
  F1 : 0.3241106719367589
```

<br>




