{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 작업형 제 2 유형\n",
    "\n",
    "### ✏️ 여행 보험 패키지 상품을 구매할 확률값을 예측하시오.\n",
    "- 제공된 데이터 목록 : train.csv, test.csv\n",
    "\n",
    "- 예측할 컬럼 : TravelInsurance(여행 보험 패키지를 구매했는지 여부, 0 : 구매 안함, 1 : 구매)\n",
    "\n",
    "- 학습용 데이터(train)을 이용하여 여행 보험 패키지 상품을 구매할 예측 모형을 만든 후 이를 평가용 데이터(test)에 적용하여 얻은 예측(가입 확률)값을 다음과 같은 형식의 csv 파일로 생성하시오. (제출한 모델의 성능은 ROC-AUC 평가지표에 따라 채점)\n",
    "\n",
    "    - 제출 csv 파일명 : result.csv\n",
    "\n",
    "    - 형태 : index, y_pred  컬럼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1490, 10) (497, 9) \n",
      "\n",
      "   Unnamed: 0  Age               Employment Type GraduateOrNot  AnnualIncome  \\\n",
      "0         888   28  Private Sector/Self Employed           Yes       1250000   \n",
      "1        1308   31  Private Sector/Self Employed           Yes       1250000   \n",
      "2         151   29  Private Sector/Self Employed           Yes       1200000   \n",
      "\n",
      "   FamilyMembers  ChronicDiseases FrequentFlyer EverTravelledAbroad  \\\n",
      "0              6                1            No                  No   \n",
      "1              7                1            No                  No   \n",
      "2              7                0            No                  No   \n",
      "\n",
      "   TravelInsurance  \n",
      "0                0  \n",
      "1                0  \n",
      "2                1   \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1490 entries, 0 to 1489\n",
      "Data columns (total 10 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   Unnamed: 0           1490 non-null   int64 \n",
      " 1   Age                  1490 non-null   int64 \n",
      " 2   Employment Type      1490 non-null   object\n",
      " 3   GraduateOrNot        1490 non-null   object\n",
      " 4   AnnualIncome         1490 non-null   int64 \n",
      " 5   FamilyMembers        1490 non-null   int64 \n",
      " 6   ChronicDiseases      1490 non-null   int64 \n",
      " 7   FrequentFlyer        1490 non-null   object\n",
      " 8   EverTravelledAbroad  1490 non-null   object\n",
      " 9   TravelInsurance      1490 non-null   int64 \n",
      "dtypes: int64(6), object(4)\n",
      "memory usage: 116.5+ KB\n",
      "None \n",
      "\n",
      "        Unnamed: 0          Age  AnnualIncome  FamilyMembers  ChronicDiseases  \\\n",
      "count  1490.000000  1490.000000  1.490000e+03    1490.000000      1490.000000   \n",
      "mean    992.277181    29.600000  9.310738e+05       4.755705         0.280537   \n",
      "std     566.637006     2.887829  3.763057e+05       1.603613         0.449412   \n",
      "min       0.000000    25.000000  3.000000e+05       2.000000         0.000000   \n",
      "25%     502.250000    28.000000  6.000000e+05       4.000000         0.000000   \n",
      "50%     994.500000    29.000000  9.000000e+05       5.000000         0.000000   \n",
      "75%    1479.750000    32.000000  1.250000e+06       6.000000         1.000000   \n",
      "max    1983.000000    35.000000  1.800000e+06       9.000000         1.000000   \n",
      "\n",
      "       TravelInsurance  \n",
      "count      1490.000000  \n",
      "mean          0.352349  \n",
      "std           0.477862  \n",
      "min           0.000000  \n",
      "25%           0.000000  \n",
      "50%           0.000000  \n",
      "75%           1.000000  \n",
      "max           1.000000   \n",
      "\n",
      "1490 \n",
      "\n",
      "       Unnamed: 0       Age  AnnualIncome  FamilyMembers  ChronicDiseases  \\\n",
      "count   1490.0000 1490.0000     1490.0000      1490.0000        1490.0000   \n",
      "mean     992.2772   29.6000   931073.8255         4.7557           0.2805   \n",
      "std      566.6370    2.8878   376305.6803         1.6036           0.4494   \n",
      "min        0.0000   25.0000   300000.0000         2.0000           0.0000   \n",
      "25%      502.2500   28.0000   600000.0000         4.0000           0.0000   \n",
      "50%      994.5000   29.0000   900000.0000         5.0000           0.0000   \n",
      "75%     1479.7500   32.0000  1250000.0000         6.0000           1.0000   \n",
      "max     1983.0000   35.0000  1800000.0000         9.0000           1.0000   \n",
      "\n",
      "       TravelInsurance  \n",
      "count        1490.0000  \n",
      "mean            0.3523  \n",
      "std             0.4779  \n",
      "min             0.0000  \n",
      "25%             0.0000  \n",
      "50%             0.0000  \n",
      "75%             1.0000  \n",
      "max             1.0000   \n",
      "\n",
      "                     Employment Type GraduateOrNot FrequentFlyer  \\\n",
      "count                           1490          1490          1490   \n",
      "unique                             2             2             2   \n",
      "top     Private Sector/Self Employed           Yes            No   \n",
      "freq                            1056          1270          1175   \n",
      "\n",
      "       EverTravelledAbroad  \n",
      "count                 1490  \n",
      "unique                   2  \n",
      "top                     No  \n",
      "freq                  1209   \n",
      "\n",
      "                     Employment Type GraduateOrNot FrequentFlyer  \\\n",
      "count                            497           497           497   \n",
      "unique                             2             2             2   \n",
      "top     Private Sector/Self Employed           Yes            No   \n",
      "freq                             361           422           395   \n",
      "\n",
      "       EverTravelledAbroad  \n",
      "count                  497  \n",
      "unique                   2  \n",
      "top                     No  \n",
      "freq                   398   \n",
      "\n",
      "Unnamed: 0             0\n",
      "Age                    0\n",
      "Employment Type        0\n",
      "GraduateOrNot          0\n",
      "AnnualIncome           0\n",
      "FamilyMembers          0\n",
      "ChronicDiseases        0\n",
      "FrequentFlyer          0\n",
      "EverTravelledAbroad    0\n",
      "TravelInsurance        0\n",
      "dtype: int64 \n",
      "\n",
      "0 \n",
      "\n",
      "TravelInsurance\n",
      "0    965\n",
      "1    525\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 1. 문제 정의\n",
    "## 여행 보험 패키지 데이터, 여행 보험 패키지 상품(TravelInsurance) 구매 여부 예측\n",
    "## - 평가 기준은 ROC-AUC\n",
    "## - label(target) : 구매여부(TravelInsurance) 0: 구매 안함, 1: 구매\n",
    "## - 제출 방식은 test 데이터로 구매 확률을 csv 로 제출(파일명 : result.csv)\n",
    "\n",
    "# 2. 라이브러리 및 데이터 불러오기\n",
    "import pandas as pd\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "\n",
    "# 3. 탐색적 데이터 분석(EDA)\n",
    "## 데이터 크기 확인\n",
    "print(train.shape, test.shape, '\\n')\n",
    "\n",
    "## train 데이터 확인 : 카테고리(문자)와 연속형(숫자) 컬럼 혼합\n",
    "## 'Unnamed: -' 이라는 알 수 없는 컬럼, TravelInsurance 라는 label 이 숫자로 된 것 확인\n",
    "print(train.head(3), '\\n')\n",
    "\n",
    "## 데이터 자료형(타입) : int64 6개, object 4개 -> object 컬럼은 인코딩 필요\n",
    "print(train.info(), '\\n')\n",
    "\n",
    "## 기초 통계 값\n",
    "## 'Unnamed: 0' 컬럼은 데이터 수와 종류가 1,490 으로 같으므로 큰 의미가 없어 전처리에서 삭제해도 삭제하지 않아도 ok\n",
    "## AnnualIncome 지수 표기법으로 표기되어있어 보기 어려우므로 판다스 설정 변경 -> '.4f' : 소수 넷째 자리까지 표기하라고 설정하는 것\n",
    "print(train.describe(), '\\n')\n",
    "print(train['Unnamed: 0'].nunique(), '\\n')\n",
    "\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "print(train.describe(), '\\n')\n",
    "\n",
    "## object 컬럼의 unique 개수 : 모두 2개씩 카테고리를 가짐\n",
    "print(train.describe(include='object'), '\\n')\n",
    "\n",
    "## test 데이터셋에 있는 object 컬럼 확인 : train 데이터와 유사한 형타\n",
    "print(test.describe(include='O'), '\\n')\n",
    "\n",
    "## 결측치 확인 : train, test 데이터에 결측치 없음\n",
    "print(train.isnull().sum(), '\\n')\n",
    "print(test.isnull().sum().sum(), '\\n')\n",
    "\n",
    "## TravelInsurance 컬럼 종류에 따른 개수 확인\n",
    "print(train['TravelInsurance'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1490, 9) (497, 9) \n",
      "\n",
      "(1490, 13) (497, 13)\n"
     ]
    }
   ],
   "source": [
    "# 4. 데이터 전처리\n",
    "## target 컬럼을 변수에 옮겨두고 자료형이 object 인 컬럼을 판다스에서 제공하는 함수를 활용해 원-핫 인코딩\n",
    "## pd.get_dummies() : 범주형 데이터만 자동으로 원-핫 인코딩 진행\n",
    "## 베이스라인에서는 레이블 인코딩 또는 원-핫 인코딩 중에서 좀 더 편한 것으로 작업하면 됨\n",
    "## 원-핫 인코딩 전과 후의 컬럼의 변화를 눈으로 확인  후 차이가 있다면 아래와 같이 의심\n",
    "## - train 과 test 범주형 컬럼의 카테고리 수가 다름 -> train 과 test 데이터를 합쳐서 인코딩 진행\n",
    "## - label 이 숫자가 아닌 범주형 데이터로 원-핫 인코딩 처리됨 -> label 데이터를 분리하고 인코딩 진행\n",
    "target = train.pop('TravelInsurance')\n",
    "print(train.shape, test.shape, '\\n')\n",
    "\n",
    "train = pd.get_dummies(train)\n",
    "test = pd.get_dummies(test)\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### 💡 train 과 test 범주형 컬럼의 카테고리 수가 다르다면?\n",
    "- train 과 test 데이터를 합쳐서 이노딩하고 다시 분할\n",
    "\n",
    "    - train 과 test 는 컬럼 수가 다르므로 합했다가 분할했을 때 test 의 'TravelInsurance' 컬럼에 생성됨\n",
    "\n",
    "        - test 에서 'TravelInsurance' 제거\n",
    "\n",
    "    - 데이터 누출(Data Leekage) 문제 야기할 수 있음\n",
    "\n",
    "        - test 데이터에만 있는 카테고리가 있을 경우 카테고리 학습 정보가 머신러닝 학습 과정에 포함되어 성능엥 영향을 미칠 수 있기 때문\n",
    "\n",
    "- 타깃 'TravelInsurance' 컬럼을 train 에서 미리 분리하고, 데이터 합치기\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1490, 9) (497, 9) \n",
      "\n",
      "(1490, 13) (497, 13)\n",
      "Index(['Unnamed: 0', 'Age', 'AnnualIncome', 'FamilyMembers', 'ChronicDiseases',\n",
      "       'Employment Type_Government Sector',\n",
      "       'Employment Type_Private Sector/Self Employed', 'GraduateOrNot_No',\n",
      "       'GraduateOrNot_Yes', 'FrequentFlyer_No', 'FrequentFlyer_Yes',\n",
      "       'EverTravelledAbroad_No', 'EverTravelledAbroad_Yes'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "\n",
    "target = train.pop('TravelInsurance')\n",
    "print(train.shape, test.shape, '\\n')\n",
    "\n",
    "combined = pd.concat([train, test])\n",
    "combined_dummies = pd.get_dummies(combined)\n",
    "n_train = len(train)\n",
    "train = combined_dummies[:n_train]\n",
    "test = combined_dummies[n_train:]\n",
    "\n",
    "print(train.shape, test.shape)\n",
    "\n",
    "print(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1192, 13) (298, 13) (1192,) (298,)\n"
     ]
    }
   ],
   "source": [
    "# 5. 검증 데이터 분할\n",
    "## train 데이터를 활용해 검증 데이터(20%) 분할\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, target, test_size=0.2, random_state=0)\n",
    "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\babys\\anaconda3\\lib\\site-packages (2.1.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\babys\\anaconda3\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\babys\\anaconda3\\lib\\site-packages (from xgboost) (1.13.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\babys\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로지스틱 회귀 : 0.7743664717348929\n",
      "의사결정 나무 : 0.726803118908382\n",
      "랜덤포레스트 : 0.8506578947368421\n",
      "xgboost : 0.8084795321637427\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 417, number of negative: 775\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001071 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 324\n",
      "[LightGBM] [Info] Number of data points in the train set: 1192, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.349832 -> initscore=-0.619777\n",
      "[LightGBM] [Info] Start training from score -0.619777\n",
      "lightGBM : 0.8198830409356724\n"
     ]
    }
   ],
   "source": [
    "# 6. 머신러닝 학습 및 평가\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "!pip install xgboost\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score   # roc-auc 는 1에 가까울수록 좋은 모델\n",
    "\n",
    "## 1. 로지스틱 회귀 모델\n",
    "lr = LogisticRegression(random_state=0)\n",
    "lr.fit(X_train, y_train)\n",
    "pred = lr.predict_proba(X_val)\n",
    "print('로지스틱 회귀 :', roc_auc_score(y_val, pred[:,1]))\n",
    "\n",
    "## 2. 의사결정 나무 모델\n",
    "dt = DecisionTreeClassifier(random_state=0)\n",
    "dt.fit(X_train, y_train)\n",
    "pred = dt.predict_proba(X_val)\n",
    "print('의사결정 나무 :', roc_auc_score(y_val, pred[:,1]))\n",
    "\n",
    "## 3. 랜덤포레스트 모델\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "pred = rf.predict_proba(X_val)\n",
    "print('랜덤포레스트 :', roc_auc_score(y_val, pred[:,1]))\n",
    "\n",
    "## 4. xgboost 모델\n",
    "xg = xgb.XGBClassifier(random_state=0)\n",
    "xg.fit(X_train, y_train)\n",
    "pred = xg.predict_proba(X_val)\n",
    "print('xgboost :', roc_auc_score(y_val, pred[:,1]))\n",
    "\n",
    "## 5. lightGBM 모델 -> LightGBMError: Do not support special JSON characters in feature name.\n",
    "### 컬럼명의 특수 문자 \":\" 때문에 발생. 컬럼명을 rename() 함수를 활용해 변경 후 재실행\n",
    "### 만약, 'Unnamed: 0' 컬럼을 삭제했다면 해당 에러 발생하지 않았을 것\n",
    "X_train.rename(columns={'Unnamed: 0' : 'Unnamed'}, inplace=True)\n",
    "X_val.rename(columns={'Unnamed: 0' : 'Unnamed'}, inplace=True)\n",
    "\n",
    "lg = lgb.LGBMClassifier(random_state=0)\n",
    "lg.fit(X_train, y_train)\n",
    "pred = lg.predict_proba(X_val)\n",
    "print('lightGBM :', roc_auc_score(y_val, pred[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.2400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  y_pred\n",
       "0      0  0.2400\n",
       "1      1  0.0800\n",
       "2      2  0.1200"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7. 예측 및 결과 파일 생성\n",
    "## 제출 양식 형태로 컬럼명을 작성하고 데이터프레임 만들기\n",
    "## index 컬럼은 test 데이터의 인덱스로 y_pred 컬럼은 1 확률값만 대입한 다음 csv 파일로 생성\n",
    "## index 파라미터는 반드시 False 로 진행\n",
    "pred = rf.predict_proba(test)\n",
    "submit = pd.DataFrame({'index':test.index, 'y_pred':pred[:,1]})\n",
    "submit.to_csv('result.csv', index=False)\n",
    "\n",
    "pd.read_csv('result.csv').head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1192, 9) (298, 9) (1192,) (298,)\n",
      "0.8610380116959064\n"
     ]
    }
   ],
   "source": [
    "# 8-1. 성능 개선\n",
    "## 인코딩 진행\n",
    "\n",
    "# 데이터 불러오기\n",
    "import pandas as pd\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "\n",
    "target = train.pop('TravelInsurance')\n",
    "\n",
    "# 레이블 인코딩 => 0.8610380116959064(원-핫 인코딩시 0.8506578947368421 이므로 레이블 인코딩 채택)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "cols = train.select_dtypes(include='object').columns\n",
    "for col in cols:\n",
    "    le = LabelEncoder()\n",
    "    train[col] = le.fit_transform(train[col])\n",
    "    test[col] = le.transform(test[col])\n",
    "    \n",
    "# 검증 데이터 분할\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, target, test_size=0.2, random_state=0)\n",
    "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)\n",
    "\n",
    "# 랜덤포레스트\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "pred = rf.predict_proba(X_val)\n",
    "print(roc_auc_score(y_val, pred[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1192, 9) (298, 9) (1192,) (298,)\n",
      "0.8612573099415205\n"
     ]
    }
   ],
   "source": [
    "# 8-2. 성능 개선\n",
    "## 스케일링 진행\n",
    "\n",
    "# 데이터 불러오기\n",
    "import pandas as pd\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "\n",
    "target = train.pop('TravelInsurance')\n",
    "\n",
    "# 스케일링 : 스케일링 전 0.8610380116959064\n",
    "from sklearn.preprocessing import StandardScaler    # 0.860233918128655\n",
    "from sklearn.preprocessing import MinMaxScaler      # 0.8606481481481483\n",
    "from sklearn.preprocessing import RobustScaler      # 0.8612573099415205 채택\n",
    "scaler = RobustScaler()\n",
    "cols = train.select_dtypes(exclude='object').columns\n",
    "train[cols] = scaler.fit_transform(train[cols])\n",
    "test[cols] = scaler.transform(test[cols])\n",
    "\n",
    "# 레이블 인코딩\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "cols = train.select_dtypes(include='object').columns\n",
    "for col in cols:\n",
    "    le = LabelEncoder()\n",
    "    train[col] = le.fit_transform(train[col])\n",
    "    test[col] = le.transform(test[col])\n",
    "    \n",
    "# 검증 데이터 분할\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, target, test_size=0.2, random_state=0)\n",
    "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)\n",
    "\n",
    "# 랜덤포레스트\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "pred = rf.predict_proba(X_val)\n",
    "print(roc_auc_score(y_val, pred[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index  y_pred\n",
      "0      0  0.2100\n",
      "1      1  0.0900\n",
      "2      2  0.1000\n"
     ]
    }
   ],
   "source": [
    "# 9. 두 번째 csv 파일 생성 후 제출\n",
    "pred = rf.predict_proba(test)\n",
    "submit = pd.DataFrame({'index':test.index, 'y_pred':pred[:,1]})\n",
    "submit.to_csv('result.csv', index=False)\n",
    "\n",
    "print(pd.read_csv('result.csv').head(3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
