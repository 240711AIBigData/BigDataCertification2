{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 작업형 제 3 유형\n",
    "\n",
    "### ✏️ [로지스틱 회귀] 조개 정보를 나타낸 데이터다. 주어진 데이터에서 300개 중 앞에서부터 210개에는 train 으로, 90개는 test 데이터로 나눈다. 모델을 학습(적합)할 때는 train 데이터를 사용하고, 예측할 때는 ㅅest 데이터를 사용한다. 모델은 다중 로지스틱 회귀를 써서 성별(gender)을 예측하되, 패널티는 부과하지 않는다\n",
    "\n",
    "- 종속변수 : gender(0: 암컷, 1: 수컷)\n",
    "\n",
    "** 패널티는 주로 L1패널티(Lasso 회귀), L2패널티(Ridge 회귀) 등이 있는데 과적합을 방지하기 위해 사용됨\n",
    "\n",
    "<br>\n",
    "\n",
    "#### [문제1-1] weight 를 독립변수, gender 를 종속변수로 사용해 로지스틱 회귀 모델을 만들고, weight 변수가 무게가 한 단위 증가할 때 수컷일 오즈비 값은? (반올림하여 소수 넷째 자리까지 계산)\n",
    "\n",
    "#### [문제1-2] gender 를 종속변수로 하고 나머지 변수돌(age, length, diameter, height, weight)을 독립변수로 사용하는 로지스틱 회귀 모델을 적합시킨 후 잔차 이탈도(Residual Deviance)를 계산하시오. (반올림하여 소수 둘째 자리까지 계산)\n",
    "\n",
    "#### [문제1-3] 독립변수 weight 만 사용해 학습한 모델에서 test 데이터의 gender 를 예측하고, Error Rage(오류율)를 구하시오. (반올림하여 소수 셋째 자리까지 계산)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age    length  diameter    height     weight  gender\n",
      "0    6  0.474627  0.211352  0.178189  78.971766       1\n",
      "1    1  0.465847  0.339388  0.170522  98.781960       1\n",
      "2    4  0.122807  0.238691  0.106924  88.792625       0\n",
      "3    4  0.204579  0.360543  0.034261   1.028847       0\n",
      "4    8  0.243458  0.358037  0.128080   6.503367       0 \n",
      "\n",
      "(300, 6)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./data/clam.csv')\n",
    "print(df.head(), '\\n')\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210, 6) \n",
      "\n",
      "   age    length  diameter    height     weight  gender\n",
      "0    6  0.474627  0.211352  0.178189  78.971766       1\n",
      "1    1  0.465847  0.339388  0.170522  98.781960       1\n",
      "2    4  0.122807  0.238691  0.106924  88.792625       0\n",
      "3    4  0.204579  0.360543  0.034261   1.028847       0\n",
      "4    8  0.243458  0.358037  0.128080   6.503367       0\n"
     ]
    }
   ],
   "source": [
    "# 데이터 분할\n",
    "train = df.iloc[:210]\n",
    "test =df.iloc[210:]\n",
    "print(train.shape, '\\n')\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.690045\n",
      "         Iterations 4\n",
      "1.0047\n"
     ]
    }
   ],
   "source": [
    "# [문제1-1]\n",
    "# 1. 로지스틱 회귀 모델 생성 및 학습\n",
    "## logit() 함수를 사용해 로지스틱 회귀 모델을 생성하고 학습\n",
    "## 모델은 gender 를 종속변수, weight 를 독립변수로 사용\n",
    "from statsmodels.formula.api import logit\n",
    "import numpy as np\n",
    "\n",
    "model = logit('gender ~ weight', data=train).fit()\n",
    "\n",
    "# 2. 오즈비 계산\n",
    "## 학습된 모델에서 weight 에 대한 계수 값 가져온 후 np.exp() 함수를 사용해 오즈비로 변환\n",
    "## round() 함수를 사용해 오즈비를 소수점 넷째 자리까지 반올림하여 출력\n",
    "## 계산된 오즈비는 weight 가 한 단위 증가할 때마다 gender 가 수컷일 확률이 얼마나 증가하는지를 나타냄\n",
    "odds_ratio = np.exp(model.params['weight'])\n",
    "print(round(odds_ratio, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.683173\n",
      "         Iterations 4\n",
      "286.93\n"
     ]
    }
   ],
   "source": [
    "# [문제1-2]\n",
    "# 1. 로지스틱 회귀 모델 생성 및 학습\n",
    "## 문제에서 요구한 독립변수를 사용해 로지스틱 회귀 모델을 적합(학습)\n",
    "from statsmodels.formula.api import logit\n",
    "formula = 'gender ~ age + length + diameter + height + weight'\n",
    "model = logit(formula, data=train).fit()\n",
    "\n",
    "# 2. 잔차이탈도\n",
    "## 잔차이탈도(residual deviance)는 모델의 적합도를 평가하는 지표, 로그 우도 값에 -2 를 곱한 값\n",
    "## 로그 우도(log-likelihood) 값이 클수록 모델이 데이터를 잘 설명한다는 뜻\n",
    "### 로지스틱 회귀 모델의 로그 우도는 모델이 주어진 데이터에 얼마나 잘 맞는지를 나타내는 지표\n",
    "print(round(-2 * model.llf, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.690045\n",
      "         Iterations 4\n",
      "0.478\n"
     ]
    }
   ],
   "source": [
    "# [문제1-3]\n",
    "# 1. test 데이터를 사용해 예측(0.5 미만: 0, 0.5 이상: 1)\n",
    "## 모델을 학습할 때는 train 데이터를 사용하고, 예측할 때는 test 데이터 사용\n",
    "## gender 를 target 변수에 옮겨두고 성별(gender)을 예측\n",
    "## 로지스틱 회귀 모델(logit)을 통해 각 관측치가 1에 속할 확률 계산\n",
    "## 이 확률이 0.5 이상이면 1로 분류, 0.5 미만이면 0으로 분류\n",
    "## 이렇게 해서 실제 범주형 예측값(0 또는 1)이 저장됨\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "## 로지스틱 회귀 모델 생성 및 학습 (독립변수 weight 만 사용)\n",
    "model = logit('gender ~ weight', data=train).fit()\n",
    "\n",
    "target = test.pop('gender')\n",
    "pred = model.predict(test)\n",
    "pred = (pred > 0.5).astype(int)\n",
    "\n",
    "# 2. 실제 값과 예측값을 사용해 정확도 계산\n",
    "## accuracy_score() 함수는 실제값(target)과 예측값(pred)을 받아 모델의 정확도 계산\n",
    "## 정확도는 예측 중에서 올바르게 예측된 비율을 의미\n",
    "accuracy = accuracy_score(target, pred)\n",
    "\n",
    "# 3. 오류율 계산\n",
    "## 오류율은 1에서 정확도를 뺀 값으로 잘못 예측된 비율을 나타냄\n",
    "error_rate = 1 - accuracy\n",
    "print(round(error_rate, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### 💡 Statsmodels 로지스틱 회귀 주요 속성 및 메서드\n",
    "\n",
    "|속성/메서드|설명|\n",
    "|:-:|-|\n",
    "|model.params|회귀 계수 (Coefficients)|\n",
    "|model.pvalues|각 독립변수에 대한 p-value|\n",
    "|model.summary()|모델의 요약 결과표 (Coefficients, Pseudo R-squared 등 포함)|\n",
    "|model.llf|모델의 로그-우도 (Log-Likelihood of the fitted model)|\n",
    "|model.llnull|Null 모델의 로그-우도|\n",
    "|model.bic|Bayesian Information Criterion (BIC)|\n",
    "|model.aic|Akaike Information Criterion (AIC)|\n",
    "|model.df_model|사용된 독립변수의 개수|\n",
    "|model.df_resid|자유도 잔차 (Residual degrees of freedom)|\n",
    "|model.pred_table()|Confusion Matrix (예측 vs 실제값)|\n",
    "|model.fittedvalues|학습 데이터에 대한 예측값 (확률)|\n",
    "|model.resid_dev|잔차 이탈도 (Deviance Residuals)|\n",
    "|model.bse|회귀 계수의 표준 오차 (Standard Errors)|\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "#### 💡 오류율(Error Rate)\n",
    "- 분류 모델에서 예측한 결과가 실제 값과 얼마나 다른지를 나타내는 지표\n",
    "\n",
    "    - 모든 예측 중에서 잘못된 예측의 비율\n",
    "\n",
    "- 오류율 = 잘못된 예측의 수 / 전체 예측의 수\n",
    "\n",
    "- 정확도(Accuracy) : 모든 예측 중 올바른 예측의 비율\n",
    "\n",
    "    - 오류율과 정확도는 서로 보완적인 관계\n",
    "\n",
    "    - 오류율이 낮을 수록 모델의 성능이 좋다고 평가\n",
    "\n",
    "        - 정확도 = 1 - 오류율\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✏️ [선형 회귀]\n",
    "\n",
    "#### [문제2-1] ERP 와 가장 상관 관계가 높은 값을 구하시오. (반올림하여 소수 셋째 자리까지 계산)\n",
    "\n",
    "#### [문제2-2] CPU 컬럼이 100 미만인 것만 찾아 ERP 를 종속변수, 나머지 변수들을 독립변수로 설정해 선형 회귀 모델을 만들고 적합한 결정 계수를 구하시오. (반올림하여 소수 셋째 자리까지 계산)\n",
    "\n",
    "#### [문제2-3] 문제 2-2에서 만든 모델에서 독립변수 중 p-value 가 가장 높은 값을 구하시오. (반올림하여 소수 셋째 자리까지 계산)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ERP  Feature1  Feature2  Feature3    CPU\n",
      "0   30.6     235.1      44.5      44.0  112.3\n",
      "1   40.3      36.6      46.4      36.1   58.6\n",
      "2   57.7      52.2      66.5       2.0   55.3\n",
      "3  128.3     196.2      59.8      57.4  103.2\n",
      "4   80.3      75.2      59.6      58.2  104.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./data/system_cpu.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               ERP  Feature1  Feature2  Feature3       CPU\n",
      "ERP       1.000000 -0.053848  0.092432  0.882194  0.092455\n",
      "Feature1 -0.053848  1.000000 -0.020095 -0.015767  0.023664\n",
      "Feature2  0.092432 -0.020095  1.000000  0.118877  0.130492\n",
      "Feature3  0.882194 -0.015767  0.118877  1.000000  0.137120\n",
      "CPU       0.092455  0.023664  0.130492  0.137120  1.000000 \n",
      "\n",
      "ERP         1.000000\n",
      "Feature3    0.882194\n",
      "CPU         0.092455\n",
      "Feature2    0.092432\n",
      "Feature1   -0.053848\n",
      "Name: ERP, dtype: float64 \n",
      "\n",
      "정답 : 0.882\n"
     ]
    }
   ],
   "source": [
    "# 문제[2-1]\n",
    "# 1. ERP 와 각 변수 사이의 상관계수 계산\n",
    "## 데이터프레임의 corr()를 사용해 모든 변수 간의 상관 계수 계산\n",
    "corr_matrix = df.corr()\n",
    "print(corr_matrix, '\\n')\n",
    "\n",
    "# 2. ERP 와 다른 변수들과의 상관계수 출력\n",
    "## ERP 변수와 다른 모든 변수들과의 상관 계수를 선택하고, 이를 내림차순(ascending=False)으로 정렬\n",
    "##  - ERP 와 가장 높은 상관 관계를 가진 변수부터 시작해 낮은 상관 계수를 가진 변수 순으로 정렬\n",
    "## 상관 계수의 절대값 중요\n",
    "##  - ex. 상관 계수가 +0.9 와 -0.95 인 두 변수가 있다면, -0.95 의 절댓값이 더 크기 때문에 음의 상관 계수를 가진 변수가 ERP 와 더 강한 상관 관계를 가짓 것으로 간주\n",
    "erp_corr = corr_matrix['ERP'].sort_values(ascending=False)\n",
    "print(erp_corr, '\\n')\n",
    "print('정답 :', round(erp_corr.values[1], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    ERP   R-squared:                       0.755\n",
      "Model:                            OLS   Adj. R-squared:                  0.736\n",
      "Method:                 Least Squares   F-statistic:                     39.30\n",
      "Date:                Thu, 28 Nov 2024   Prob (F-statistic):           5.36e-15\n",
      "Time:                        17:33:02   Log-Likelihood:                -260.40\n",
      "No. Observations:                  56   AIC:                             530.8\n",
      "Df Residuals:                      51   BIC:                             540.9\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     51.4133     19.112      2.690      0.010      13.045      89.782\n",
      "Feature1      -0.0242      0.059     -0.409      0.684      -0.143       0.094\n",
      "Feature2       0.0602      0.106      0.569      0.572      -0.152       0.273\n",
      "Feature3       1.4126      0.113     12.458      0.000       1.185       1.640\n",
      "CPU           -0.4651      0.234     -1.985      0.053      -0.936       0.005\n",
      "==============================================================================\n",
      "Omnibus:                        3.758   Durbin-Watson:                   1.762\n",
      "Prob(Omnibus):                  0.153   Jarque-Bera (JB):                2.757\n",
      "Skew:                           0.436   Prob(JB):                        0.252\n",
      "Kurtosis:                       3.648   Cond. No.                         780.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "정답 : 0.755\n"
     ]
    }
   ],
   "source": [
    "# [문제2-2]\n",
    "# 1. \n",
    "cond = df['CPU'] < 100\n",
    "filtered_df = df[cond]\n",
    "\n",
    "# 2. \n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "model = ols('ERP ~ Feature1 + Feature2 + Feature3 + CPU', data=filtered_df).fit()\n",
    "\n",
    "# \n",
    "print(model.summary())\n",
    "print('정답 :', round(model.rsquared, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### 💡 Statsmodels 선형 회귀 주요 속성 및 메서드\n",
    "\n",
    "|속성/메서드|설명|\n",
    "|:-:|-|\n",
    "|model.params|회귀 계수 (Coefficients)|\n",
    "|model.pvalues|각 독립변수에 대한 p-value|\n",
    "|model.rsquared|결정 계수 (R-squared, 모델 적합도)|\n",
    "|model.rsquared_adj|조정된 결정 계수 (Adjusted R-squared)|\n",
    "|model.summary()|모델 요약 결과표 (Coefficients, R-squared 등 포함)|\n",
    "|model.fvalue|F-statistic 값 (모델 전체 유의성 테스트)|\n",
    "|model.f_pvalue|F-statistic에 대한 p-value|\n",
    "|model.aic|Akaike Information Criterion (AIC)|\n",
    "|model.bic|Bayesian Information Criterion (BIC)|\n",
    "|model.resid|잔차 (Residuals)|\n",
    "|model.fittedvalues|학습 데이터에 대한 예측값|\n",
    "|model.predict()|새로운 데이터에 대한 예측|\n",
    "\n",
    "<br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가장 높은 p-value 를 가진 변수명 : Feature1\n",
      "정답(가장 높은 p-value) : 0.684\n"
     ]
    }
   ],
   "source": [
    "# [문제2-3]\n",
    "# 1. p-value 에서 최대값과 해당 변수명 찾기\n",
    "max_pvalue = model.pvalues.max()    # 가장 높은 p-value\n",
    "max_pvalue_variable = model.pvalues.idxmax()    # 가장 높은 p-value 를 가진 변수명\n",
    "\n",
    "# 2. 결과 출력\n",
    "print('가장 높은 p-value 를 가진 변수명 :', max_pvalue_variable)\n",
    "print('정답(가장 높은 p-value) :', round(max_pvalue, 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
