{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 작업형 제 2 유형\n",
    "\n",
    "### ✏️ 고객의 개인 정보와 행동 패턴을 기반으로 고객의 세분화(Segmentation) 결과를 예측하시오\n",
    "- 제공된 데이터 목록 : train.csv, test.csv\n",
    "- 예측할 컬럼 : Segmentation(고객 세분화 결과값 : 1, 2, 3, 4)\n",
    "    - 학습용 데이터(train.csv)를 이용하여 고객의 세분화 결과를 예측하는 모델을 만든 후 이를 평가용 데이터(test.csv)에 적용하여 얻은 예측값을 다음과 같은 형식의 csv 파일로 생성하시오\n",
    "\n",
    "        - 제출 파일은 다음 2개의 컬럼을 포함해야 한다\n",
    "\n",
    "            - ID : 고객 식별자\n",
    "\n",
    "            - Segmentation : 예측된 세분화 결과\n",
    "\n",
    "            - 제출 파일명 : result.csv\n",
    "\n",
    "        - 제출한 모델의 성능은 Macro F1 Score 평가지표에 따라 채점한다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 문제 정의\n",
    "## 고객 정의(Segmentation) 데이터, 고객의 개인 정보와 행동 패턴을 기반으로 고객 세분화를 예측\n",
    "\n",
    "# 2. 라이브러리 및 데이터 불러오기\n",
    "import pandas as pd\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6665, 11) (2154, 10) \n",
      "\n",
      "       ID  Gender Ever_Married  Age Graduated  Profession  Work_Experience  \\\n",
      "0  462809    Male           No   22        No  Healthcare              1.0   \n",
      "1  466315  Female          Yes   67       Yes    Engineer              1.0   \n",
      "2  461735    Male          Yes   67       Yes      Lawyer              0.0   \n",
      "3  461319    Male          Yes   56        No      Artist              0.0   \n",
      "4  460156    Male           No   32       Yes  Healthcare              1.0   \n",
      "\n",
      "  Spending_Score  Family_Size  Var_1  Segmentation  \n",
      "0            Low          4.0  Cat_4             4  \n",
      "1            Low          1.0  Cat_6             2  \n",
      "2           High          2.0  Cat_6             2  \n",
      "3        Average          2.0  Cat_6             3  \n",
      "4            Low          3.0  Cat_6             3   \n",
      "\n",
      "       ID  Gender Ever_Married  Age Graduated  Profession  Work_Experience  \\\n",
      "0  458989  Female          Yes   36       Yes    Engineer              0.0   \n",
      "1  458994    Male          Yes   37       Yes  Healthcare              8.0   \n",
      "2  459000    Male          Yes   59        No   Executive             11.0   \n",
      "3  459003    Male          Yes   47       Yes      Doctor              0.0   \n",
      "4  459005    Male          Yes   61       Yes      Doctor              5.0   \n",
      "\n",
      "  Spending_Score  Family_Size  Var_1  \n",
      "0            Low          1.0  Cat_6  \n",
      "1        Average          4.0  Cat_6  \n",
      "2           High          2.0  Cat_6  \n",
      "3           High          5.0  Cat_4  \n",
      "4            Low          3.0  Cat_6   \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6665 entries, 0 to 6664\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   ID               6665 non-null   int64  \n",
      " 1   Gender           6665 non-null   object \n",
      " 2   Ever_Married     6665 non-null   object \n",
      " 3   Age              6665 non-null   int64  \n",
      " 4   Graduated        6665 non-null   object \n",
      " 5   Profession       6665 non-null   object \n",
      " 6   Work_Experience  6665 non-null   float64\n",
      " 7   Spending_Score   6665 non-null   object \n",
      " 8   Family_Size      6665 non-null   float64\n",
      " 9   Var_1            6665 non-null   object \n",
      " 10  Segmentation     6665 non-null   int64  \n",
      "dtypes: float64(2), int64(3), object(6)\n",
      "memory usage: 572.9+ KB\n",
      "None \n",
      "\n",
      "                 ID          Age  Work_Experience  Family_Size  Segmentation\n",
      "count    6665.00000  6665.000000      6665.000000  6665.000000   6665.000000\n",
      "mean   463519.84096    43.536084         2.629107     2.841110      2.542836\n",
      "std      2566.43174    16.524054         3.405365     1.524743      1.122723\n",
      "min    458982.00000    18.000000         0.000000     1.000000      1.000000\n",
      "25%    461349.00000    31.000000         0.000000     2.000000      2.000000\n",
      "50%    463575.00000    41.000000         1.000000     2.000000      3.000000\n",
      "75%    465741.00000    53.000000         4.000000     4.000000      4.000000\n",
      "max    467974.00000    89.000000        14.000000     9.000000      4.000000 \n",
      "\n",
      "       Gender Ever_Married Graduated Profession Spending_Score  Var_1\n",
      "count    6665         6665      6665       6665           6665   6665\n",
      "unique      2            2         2          9              3      7\n",
      "top      Male          Yes       Yes     Artist            Low  Cat_6\n",
      "freq     3677         3944      4249       2192           3999   4476 \n",
      "\n",
      "       Gender Ever_Married Graduated Profession Spending_Score  Var_1\n",
      "count    2154         2154      2154       2154           2154   2154\n",
      "unique      2            2         2          9              3      7\n",
      "top      Male          Yes       Yes     Artist            Low  Cat_6\n",
      "freq     1184         1272      1345        696           1326   1421 \n",
      "\n",
      "0 \n",
      "\n",
      "0 \n",
      "\n",
      "Segmentation\n",
      "4    1757\n",
      "3    1720\n",
      "1    1616\n",
      "2    1572\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 3. 탐색적 데이터 분석(EDA)\n",
    "## 데이터 크기\n",
    "print(train.shape, test.shape, '\\n')\n",
    "\n",
    "## 데이터 샘플 확인\n",
    "print(train.head(), '\\n')\n",
    "print(test.head(), '\\n')\n",
    "\n",
    "## 데이터 자료형(타입)\n",
    "print(train.info(), '\\n')\n",
    "\n",
    "## 기초 통계량\n",
    "print(train.describe(), '\\n')\n",
    "\n",
    "## object 의 unique 개수\n",
    "print(train.describe(include='object'), '\\n')\n",
    "print(test.describe(include='object'), '\\n')\n",
    "\n",
    "## 결측치 여부\n",
    "print(train.isnull().sum().sum(), '\\n')\n",
    "print(test.isnull().sum().sum(), '\\n')\n",
    "\n",
    "## Segmentation 컬럼 종류에 따른 개수\n",
    "print(train['Segmentation'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6665, 10) (2154, 10) \n",
      "\n",
      "(6665, 29) (2154, 29)\n"
     ]
    }
   ],
   "source": [
    "# 4. 데이터 전처리\n",
    "## 자료형이 object 인 컬럼을 원-핫 인코딩\n",
    "target = train.pop('Segmentation')\n",
    "print(train.shape, test.shape, '\\n')\n",
    "\n",
    "train = pd.get_dummies(train)\n",
    "test = pd.get_dummies(test)\n",
    "\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5332, 29) (1333, 29) (5332,) (1333,)\n"
     ]
    }
   ],
   "source": [
    "# 5. 검증 데이터 분할\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, target, test_size=0.2, random_state=0)\n",
    "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\babys\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로지스틱 회귀 : 0.33131634079352795\n",
      "의사결정나무 : 0.42783783376258655\n",
      "랜덤 포레스트 : 0.5020137672414862\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000176 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 398\n",
      "[LightGBM] [Info] Number of data points in the train set: 5332, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score -1.414444\n",
      "[LightGBM] [Info] Start training from score -1.434710\n",
      "[LightGBM] [Info] Start training from score -1.372881\n",
      "[LightGBM] [Info] Start training from score -1.326597\n",
      "lightGBM : 0.5392434827587952\n"
     ]
    }
   ],
   "source": [
    "# 머신러닝 학습 및 평가\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# !pip install xgboost\n",
    "# import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# 로지스틱 회귀\n",
    "lr = LogisticRegression(random_state=0)\n",
    "lr.fit(X_train, y_train)\n",
    "pred = lr.predict(X_val)\n",
    "print('로지스틱 회귀 :', f1_score(y_val, pred, average='macro'))\n",
    "\n",
    "# 의사결정 나무\n",
    "dt = DecisionTreeClassifier(random_state=0)\n",
    "dt.fit(X_train, y_train)\n",
    "pred = dt.predict(X_val)\n",
    "print('의사결정나무 :', f1_score(y_val, pred, average='macro'))\n",
    "\n",
    "# 랜덤 포레스트\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "pred = rf.predict(X_val)\n",
    "print('랜덤 포레스트 :', f1_score(y_val, pred, average='macro'))\n",
    "\n",
    "# xgboost -> 에러 발생 ValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3], got [1 2 3 4]\n",
    "## Xgboost 분류 모델은 예측 클래스가 0 부터 시작해야 함(0, 1, 2, 3 으로 있어야 정상작동)\n",
    "## 예측 전후에 값 변경이 필요하므로 생략\n",
    "# xg = xgb.XGBClassifier(random_state=0)\n",
    "# xg.fit(X_train, y_train)\n",
    "# pred = xg.predict(X_val)\n",
    "# print('xgboost :', f1_score(y_val, pred, average='macro'))\n",
    "\n",
    "# lightGBM -> 채택\n",
    "lg = lgb.LGBMClassifier(random_state=0)\n",
    "lg.fit(X_train, y_train)\n",
    "pred = lg.predict(X_val)\n",
    "print('lightGBM :', f1_score(y_val, pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ID  Segmentation\n",
      "0  458989             2\n",
      "1  458994             3\n",
      "2  459000             3\n",
      "3  459003             2\n",
      "4  459005             2\n"
     ]
    }
   ],
   "source": [
    "# 예측 및 결과 파일 생성\n",
    "pred = lg.predict(test)\n",
    "submit = pd.DataFrame({'ID':test['ID'], 'Segmentation':pred})\n",
    "submit.to_csv('result.csv', index=False)\n",
    "\n",
    "print(pd.read_csv('result.csv').head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5332, 28) (1333, 28) (5332,) (1333,)\n",
      "0.5277491575057244\n"
     ]
    }
   ],
   "source": [
    "# 8-1. 성능 개선(ID 삭제)\n",
    "\n",
    "# 데이터 불러오기\n",
    "import pandas as pd\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "\n",
    "target = train.pop('Segmentation')\n",
    "\n",
    "# ID 제외 -> 삭제 전에는 0.5392434827587952, 삭제 후에는 0.5277491575057244 이므로 채택하지 않음\n",
    "train.drop('ID', axis=1, inplace=True)\n",
    "test_id = test.pop('ID')\n",
    "\n",
    "# 원-핫 인코딩\n",
    "train = pd.get_dummies(train)\n",
    "test = pd.get_dummies(test)\n",
    "\n",
    "# 검증 데이터 분할\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, target, test_size=0.2, random_state=0)\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, target, test_size=0.2, random_state=0)\n",
    "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)\n",
    "\n",
    "# LightGBM\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import f1_score\n",
    "lg = lgb.LGBMClassifier(random_state=0, verbose=-1)\n",
    "lg.fit(X_train, y_train)\n",
    "pred = lg.predict(X_val)\n",
    "print(f1_score(y_val, pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5332, 10) (1333, 10) (5332,) (1333,)\n",
      "0.5253104251107019\n"
     ]
    }
   ],
   "source": [
    "# 8-2. 성능 개선(인코딩)\n",
    "\n",
    "# 데이터 불러오기\n",
    "import pandas as pd\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "\n",
    "target = train.pop('Segmentation')\n",
    "\n",
    "# 레이블 인코딩 -> 원-핫 : 0.5392434827587952, 레이블 : 0.5253104251107019 이므로 채택 X\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "cols = train.select_dtypes(include='object').columns\n",
    "for col in cols:\n",
    "    le = LabelEncoder()\n",
    "    train[col] = le.fit_transform(train[col])\n",
    "    test[col] = le.transform(test[col])\n",
    "\n",
    "# 검증 데이터 분할\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, target, test_size=0.2, random_state=0)\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, target, test_size=0.2, random_state=0)\n",
    "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)\n",
    "\n",
    "# LightGBM\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import f1_score\n",
    "lg = lgb.LGBMClassifier(random_state=0, verbose=-1)\n",
    "lg.fit(X_train, y_train)\n",
    "pred = lg.predict(X_val)\n",
    "print(f1_score(y_val, pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5332, 29) (1333, 29) (5332,) (1333,)\n",
      "0.5412871352631483\n"
     ]
    }
   ],
   "source": [
    "# 8-3. 성능 개선(스케일링)\n",
    "\n",
    "# 데이터 불러오기\n",
    "import pandas as pd\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "\n",
    "target = train.pop('Segmentation')\n",
    "\n",
    "# 스케일링 -> 전 : 0.5392434827587952\n",
    "from sklearn.preprocessing import StandardScaler    # 0.5412871352631483 채택\n",
    "from sklearn.preprocessing import MinMaxScaler      # 0.5346995165417529\n",
    "from sklearn.preprocessing import RobustScaler      # 0.536902942390099\n",
    "scaler = StandardScaler()\n",
    "cols = train.select_dtypes(exclude='object').columns\n",
    "train[cols] = scaler.fit_transform(train[cols])\n",
    "test[cols] = scaler.transform(test[cols])\n",
    "\n",
    "# 원-핫 인코딩\n",
    "train = pd.get_dummies(train)\n",
    "test = pd.get_dummies(test)\n",
    "\n",
    "# 검증 데이터 분할\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, target, test_size=0.2, random_state=0)\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, target, test_size=0.2, random_state=0)\n",
    "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)\n",
    "\n",
    "# LightGBM\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import f1_score\n",
    "lg = lgb.LGBMClassifier(random_state=0, verbose=-1)\n",
    "lg.fit(X_train, y_train)\n",
    "pred = lg.predict(X_val)\n",
    "print(f1_score(y_val, pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ID  Segmentation\n",
      "0 -1.765557             2\n",
      "1 -1.763608             3\n",
      "2 -1.761270             3\n",
      "3 -1.760101             2\n",
      "4 -1.759322             2\n"
     ]
    }
   ],
   "source": [
    "# 9. 최종 파일 제출\n",
    "pred = lg.predict(test)\n",
    "submit = pd.DataFrame({'ID':test['ID'], 'Segmentation':pred})\n",
    "submit.to_csv('result.csv', index=False)\n",
    "\n",
    "print(pd.read_csv('result.csv').head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
